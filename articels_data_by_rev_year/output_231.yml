- Affiliation of the first author: "faculty of computer and information science, university\
    \ of ljubljana, tr\u017Ea\u0161ka 25, si-1000 ljubljana, slovenia"
  Affiliation of the last author: "faculty of computer and information science, university\
    \ of ljubljana, tr\u017Ea\u0161ka 25, si-1000 ljubljana, slovenia"
  Figure 1 Link: articels_figures_by_rev_year\2014\Data_Fusion_by_Matrix_Factorization\figure_1.jpg
  Figure 1 caption: Conceptual fusion configuration for four object types, mathcal
    E1, mathcal E2, mathcal E3 and mathcal E4 , equivalently represented by the graph
    of relations between object types (a) and the block-based matrix structure (b).
    Each data source relates a pair of object types, denoted by arcs in a graph (a)
    or matrices with shades of gray in block matrix (b). For example, data matrix
    mathbf R23 relates object types mathcal E2 and mathcal E3 . Some relations are
    entirely missing. For instance, there is no data source relating objects from
    mathcal E3 and mathcal E1 , as there is no arc linking nodes mathcal E3 and mathcal
    E1 in (a) or equivalently, a matrix mathbf R31 is missing in (b). Relations can
    be asymmetric, such that mathbf R23 ne mathbf R32T . Constraints denoted by loops
    in (a) or matrices with blue entries in (b) relate objects of the same type. In
    our example configuration, constraints are provided for object types mathcal E2
    (one constraint matrix) and mathcal E4 (three constraint matrices).
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Data_Fusion_by_Matrix_Factorization\figure_2.jpg
  Figure 2 caption: Factorization algorithm of proposed data fusion approach (DFMF).
  Figure 3 Link: articels_figures_by_rev_year\2014\Data_Fusion_by_Matrix_Factorization\figure_3.jpg
  Figure 3 caption: The fusion configuration for gene function prediction task in
    D. discoideum. Some relations are entirely missing, for instance R 23 . Nodes
    represent object types used in our study. Edges correspond to relation and constraint
    matrices. The arc that represents the target matrix R 12 and its object types
    are highlighted.
  Figure 4 Link: articels_figures_by_rev_year\2014\Data_Fusion_by_Matrix_Factorization\figure_4.jpg
  Figure 4 caption: The fusion configuration for the prediction of pharmacologic actions
    of chemicals, with object types denoted with nodes and relations between them
    with edges. The edge representing the target relation and its corresponding data
    matrix R 12 is highlighted.
  Figure 5 Link: articels_figures_by_rev_year\2014\Data_Fusion_by_Matrix_Factorization\figure_5.jpg
  Figure 5 caption: "Adding new data sources (a) or incorporating more object-type-specific\
    \ constraints in \u0398 1 (b) both increase the accuracy of matrix factorization-based\
    \ models for gene function prediction task."
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.99
  Gender of the first author: female
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: "Marinka \u017Ditnik"
  Name of the last author: "Bla\u017E Zupan"
  Number of Figures: 5
  Number of Tables: 3
  Number of authors: 2
  Paper title: Data Fusion by Matrix Factorization
  Publication Date: 2014-07-29 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Cross-Validated F 1 and AUC Accuracy Scores for Fusion by
      Matrix Factorization (DFMF), Kernel-Based Method (MKL), Random Forests (RF)
      and Relational Learning-Based Matrix Factorization (tri-SPMF)
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Gene Ontology Term-Specific Cross-Validated F 1 and AUC Accuracy
      Scores for Fusion by Matrix Factorization (DFMF),Kernel-Based Method (MKL),
      Random Forests (RF) and Relational Learning-Based Matrix Factorization (tri-SPMF)
  Table 3 caption:
    table_text: TABLE 3 Effect of Initialization Algorithm on Reconstruction Error
      of DFMF's Factorization Model
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2343973
- Affiliation of the first author: "instituto universitario para el desarrollo tecnol\xF3\
    gico y la innovaci\xF3n en comunicaciones, universidad de las palmas de gran canaria,\
    \ las palmas, spain"
  Affiliation of the last author: "instituto universitario para el desarrollo tecnol\xF3\
    gico y la innovaci\xF3n en comunicaciones, universidad de las palmas de gran canaria,\
    \ las palmas, spain"
  Figure 1 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_1.jpg
  Figure 1 caption: Motor equivalence approach to synthetic off-line signature generation.
  Figure 10 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_10.jpg
  Figure 10 caption: Six possible synthetic identities with three genuine specimens
    (first three columns) and three possible forged signatures (last three columns).
    The first four signatures are composed of text plus flourish, the fifth example
    has only text and the sixth is a simple flourish.
  Figure 2 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_2.jpg
  Figure 2 caption: (a) Grid of trajectory points with their labels of the letter
    trajectory plan for letter 'P'; (b) Text trajectory plan for 'Peter' obtained
    by concatenating the letter trajectory plans. The text trajectory plan is depicted
    in dark magenta and the link plan between letters in yellow.
  Figure 3 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_3.jpg
  Figure 3 caption: "Signature envelope, text and flourish trajectory plan of \u201C\
    james smith\u201D."
  Figure 4 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_4.jpg
  Figure 4 caption: "a) Trajectory plan of letters \u201Cjames\u201D with stroke division\
    \ marked with a circle and each consecutive stroke with change in color; b) Velocity\
    \ profile vft pased on scalar Sigma lognormal normalized to maximum amplitude\
    \ equal to one; and c) The resulting handwriting word after applying the finger\
    \ control motor approach."
  Figure 5 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_5.jpg
  Figure 5 caption: a) Trajectory plan of the signature, b) result of applying the
    finger kinematic filter, c) result of filtering by the forearm kinematic filter
    and, d) signature after applying the wrist kinematic filter.
  Figure 6 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_6.jpg
  Figure 6 caption: Real signature stroke detail from GPDS database (left); detail
    of synthetic (right).
  Figure 7 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_7.jpg
  Figure 7 caption: Distribution of modeled features from real off-line signatures
    from MCYT and GPDS database and their approximated pdfs.
  Figure 8 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_8.jpg
  Figure 8 caption: Definition of the distance between columns dci and rows dfi of
    the grid trajectory points and the radius vl and vbl for within word letter class
    variability.
  Figure 9 Link: articels_figures_by_rev_year\2014\Static_Signature_Synthesis_A_Neuromotor_Inspired_Approach_for_Biometrics\figure_9.jpg
  Figure 9 caption: Influence of increasing the kinetic filters length LPsif , LPsih
    and LPsiw on the signature readability.
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.97
  Name of the first author: Miguel A. Ferrer
  Name of the last author: Aythami Morales
  Number of Figures: 11
  Number of Tables: 4
  Number of authors: 3
  Paper title: 'Static Signature Synthesis: A Neuromotor Inspired Approach for Biometrics'
  Publication Date: 2014-07-29 00:00:00
  Table 1 caption:
    table_text: TABLE 1 EER (Percent) for Random Forgeries for 150 Synthetic Users
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 EER (Percent) for Skilled Forgeries with 150 Synthetic Users
  Table 3 caption:
    table_text: TABLE 3 Results of the Perceptual Experiment
  Table 4 caption:
    table_text: TABLE 4 EER for Random Forgeries of the Same Synthetic DB with Different
      Pen Configurations and Number of Users
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2343981
- Affiliation of the first author: school of computer engineering, nanyang technological
    university, singapore
  Affiliation of the last author: school of computer engineering, nanyang technological
    university, singapore
  Figure 1 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_1.jpg
  Figure 1 caption: 'Three graphs that display information in IrisCodes, their masks
    and Gabor filters: (a) a statistical dependence graph, (b) a Gabor graph and (c)
    a mask correlation graph.'
  Figure 10 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_10.jpg
  Figure 10 caption: The correlation between the elements of Psi rm UBIRIS and Psi
    rm WVU . (a) a plot of the selected elements of Psi rm WVU against the corresponding
    elements of Psi rm UBIRIS and (b) the locations of the selected elements to compute
    (a). The rows and columns of (b) represent bit locations and the size of (b) is
    2,048 by 2,048. (Color figure. To see clearly the images, please read the electronic
    version.)
  Figure 2 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_2.jpg
  Figure 2 caption: Examples of images removed from the UBIRIS.v1 database. (Color
    figure).
  Figure 3 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_3.jpg
  Figure 3 caption: Iris texture in different channels. (a) is a color image and (b),
    (c) and (d) are the R, G and B components of (a), respectively (Color figure).
  Figure 4 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_4.jpg
  Figure 4 caption: "The relationship between < I \xAF , g k > and bit probabilities.\
    \ (a) The results from the UBIRIS.v1 database and (b) results from the WVU database.\
    \ One outlier in (a) with < I \xAF , g k >>0.1 is not shown (Color figure)."
  Figure 5 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_5.jpg
  Figure 5 caption: The left column shows original images and the right column shows
    images modified by the Equation hat I(x,y) = (0.5 times A(x,y) + 1)I(x,y) .
  Figure 6 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_6.jpg
  Figure 6 caption: The relationship between < bar I,gk > and bit probabilities computed
    from the modified iris images. (a) The results from the UBIRIS.v1 database and
    (b) results from the WVU database (Color figure).
  Figure 7 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_7.jpg
  Figure 7 caption: The pseudo code of the resampling algorithm.
  Figure 8 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_8.jpg
  Figure 8 caption: The adjacency matrix of the statistical dependence graph of the
    UBIRIS.v1 database. The matrix is obtained from the proposed resampling algorithm
    (Fig. 7). Its rows and columns represent bit locations and its size is 2,048 by
    2,048.
  Figure 9 Link: articels_figures_by_rev_year\2014\A_Statistical_Analysis_of_IrisCode_and_Its_Security_Implications\figure_9.jpg
  Figure 9 caption: A comparison of the first 256 bits of the adjacency matrixes of
    the statistical dependence graphs obtained from (a) the standard Chi-square statistic
    and correlation coefficient and (b)-(c) the proposed resampling algorithm ( Fig.
    7) on the UBIRIS.v1 and WVU databases, respectively. The rows and columns of these
    matrixes represent bit locations. All matrix sizes are 256 by 256. (To see clearly
    the images, please read the electronic version.)
  First author gender probability: 0.98
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.98
  Name of the first author: Adams Wai-Kin Kong
  Name of the last author: Adams Wai-Kin Kong
  Number of Figures: 16
  Number of Tables: 0
  Number of authors: 1
  Paper title: A Statistical Analysis of IrisCode and Its Security Implications
  Publication Date: 2014-07-29 00:00:00
  Table 1 caption:
    table_text: Not Available
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2343959
- Affiliation of the first author: institute of systems and robotics, university of
    coimbra, coimbra, portugal
  Affiliation of the last author: institute of systems and robotics, university of
    coimbra, coimbra, portugal
  Figure 1 Link: articels_figures_by_rev_year\2014\HighSpeed_Tracking_with_Kernelized_Correlation_Filters\figure_1.jpg
  Figure 1 caption: "Qualitative results for the proposed KCF, compared with the top-performing\
    \ Struck and TLD. Best viewed on a high-resolution screen. The chosen kernel is\
    \ Gaussian, on HOG features. These snapshots were taken at the midpoints of the\
    \ 50 videos of a recent benchmark [11]. Missing trackers are denoted by an \u201C\
    x\u201D. KCF outperforms both Struck and TLD, despite its minimal implementation\
    \ and running at 172 FPS (see Algorithm 1, and Table 1 )."
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\HighSpeed_Tracking_with_Kernelized_Correlation_Filters\figure_2.jpg
  Figure 2 caption: Illustration of a circulant matrix. The rows are cyclic shifts
    of a vector image, or its translations in 1D. The same properties carry over to
    circulant matrices containing 2D images.
  Figure 3 Link: articels_figures_by_rev_year\2014\HighSpeed_Tracking_with_Kernelized_Correlation_Filters\figure_3.jpg
  Figure 3 caption: Examples of vertical cyclic shifts of a base sample. Our Fourier
    domain formulation allows us to train a tracker with all possible cyclic shifts
    of a base sample, both vertical and horizontal, without iterating them explicitly.
    Artifacts from the wrapped-around edges can be seen (top of the left-most image),
    but are mitigated by the cosine window and padding.
  Figure 4 Link: articels_figures_by_rev_year\2014\HighSpeed_Tracking_with_Kernelized_Correlation_Filters\figure_4.jpg
  Figure 4 caption: Precision plot for all 50 sequences. The proposed trackers (bold)
    outperform state-of-the-art systems, such as TLD and Struck, which are more complicated
    to implement and much slower (see Table 1). Best viewed in color.
  Figure 5 Link: articels_figures_by_rev_year\2014\HighSpeed_Tracking_with_Kernelized_Correlation_Filters\figure_5.jpg
  Figure 5 caption: 'Precision plot for sequences with attributes: occlusion, non-rigid
    deformation, out-of-view target, and background clutter. The HOG variants of the
    proposed trackers (bold) are the most resilient to all of these nuisances. Best
    viewed in color.'
  Figure 6 Link: articels_figures_by_rev_year\2014\HighSpeed_Tracking_with_Kernelized_Correlation_Filters\figure_6.jpg
  Figure 6 caption: Regression targets mathbf y , following a Gaussian function with
    spatial bandwidth s (white indicates a value of 1, black a value of 0). (a) Placing
    the peak in the middle will unnecessarily cause the detection output to be shifted
    by half a window (discussed in Appendix A.1). (b) Placing the peak at the top-left
    element (and wrapping around) correctly centers the detection output.
  Figure 7 Link: articels_figures_by_rev_year\2014\HighSpeed_Tracking_with_Kernelized_Correlation_Filters\figure_7.jpg
  Figure 7 caption: Precision plots for six attributes of the dataset. Best viewed
    in color. In-plane rotation was left out due to space constraints. Its results
    are virtually identical to those for out-of-plane rotation (above), since they
    share almost the same set of sequences.
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: "Jo\xE3o F. Henriques"
  Name of the last author: Jorge Batista
  Number of Figures: 7
  Number of Tables: 2
  Number of authors: 3
  Paper title: High-Speed Tracking with Kernelized Correlation Filters
  Publication Date: 2014-08-01 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Summary of Experimental Results on the 50 Videos Dataset
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Parameters Used in All Experiments
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2345390
- Affiliation of the first author: "iie, universidad de la rep\xFAblica, montevideo,\
    \ uruguay"
  Affiliation of the last author: cmla, ens cachan, cachan, france
  Figure 1 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_1.jpg
  Figure 1 caption: "Illustration of the complexity of the point alignment problem:\
    \ Exactly the same set of aligned dots is present in the three images, but it\
    \ is only perceived as such in the first one. The second one is a classic \u201C\
    masking by texture\u201D case and the third shows a \u201Cmasking by structure\u201D\
    , often called \u201CGestalt conflict\u201D."
  Figure 10 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_10.jpg
  Figure 10 caption: Result of Hall et al. [28]. Each detection is represented by
    a thin rectangle, surrounded by the local window. In the following results a 20times
    20 candidate center grid was used, a 5 degree angle step, u=7 and v=3 . (a) Input
    set of 186 points. (b) Result of the method for a=0.2 , b=0.4 , and c=0.02 . (c)
    Result of the method for a=0.3 , b=0.6 , and c=0.02 . (d) Result of the method
    for a=0.05 , b=0.6 , and c=0.005 .
  Figure 2 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_2.jpg
  Figure 2 caption: A schematic representation of the evaluated rectangle. In a domain
    with N points, there are fracN(N-1)2W possible rectangles. In this example, N
    = 47 and k(r,mathbf x) = 8 among them are inside the rectangle r .
  Figure 3 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_3.jpg
  Figure 3 caption: Results from the basic point alignment detector (Algorithm 1).
    (a) and (c) are the input data, and (b) and (d) are the corresponding results.
    Each detection is represented by a rectangle. In (b) the algorithm correctly detects
    the obvious alignment. Notice that multiple and redundant rectangles were detected;
    this issue will be dealt with in Section 6. The data set (c) contains the same
    set of points in (a) plus added noise points. The aligned points are still present
    but hardly perceptible. The algorithm handles correctly this masking phenomenon
    and produces no detection.
  Figure 4 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_4.jpg
  Figure 4 caption: Local vs. global density estimation. (a) The set of points. (b)
    Alignments found using global density estimation (Algorithm 1). The many detected
    rectangles indeed have a high point density compared to the average image density
    used as background model. (c) Alignments found using local density estimation
    (Algorithm 2). The local density is lower on the border, hence the deceptive detection.
    (d) No alignment is found when the local density is estimated by the maximum density
    on both sides of the alignment (Algorithm 3).
  Figure 5 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_5.jpg
  Figure 5 caption: 'Left: The point density is estimated in the local window R surrounding
    the alignment r . Right: In a refined version of the algorithm, the density of
    points is measured on each side of the evaluated rectangle. The maximum of the
    densities in R1 and R3 is taken as an estimation of the point density in both
    R1 and R3 .'
  Figure 6 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_6.jpg
  Figure 6 caption: 'Left: Dot pattern with two point clusters but no alignment. Center:
    Result of Algorithm 3. A thin rectangle with a high point density was found, hence
    a false detection. Right: Algorithm 4 divides the rectangle into boxes and counts
    the occupied ones, avoiding this misleading cluster effect. The occupied boxes
    are marked in red. No alignment is detected.'
  Figure 7 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_7.jpg
  Figure 7 caption: 'Redundant detections. Left: point pattern. Center: alignments
    found by Algorithm 4. Red means the most meaningful and blue the least meaningful
    detections. Right: Result of the masking process.'
  Figure 8 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_8.jpg
  Figure 8 caption: 'Examples of two alternative formulations of the masking process.
    Left: Set of points. Center: The Exclusion Principle as defined in [15], a validated
    gestalt prevents others from using its points. The vertical alignments (evaluated
    first) mask the horizontal ones. Right: The Masking Principle, described in the
    text, which solves the ambiguities without forbidding basic elements to participate
    of two different structures.'
  Figure 9 Link: articels_figures_by_rev_year\2014\A_Contrario_D_Point_Alignment_Detection\figure_9.jpg
  Figure 9 caption: 'Result of Hall et al. [28] on a set of 100 uniform and independent
    random points. Each detection is represented by a thin rectangle, surrounded by
    the local window. Left: The same parameters as in [28, Section 3.1] were used:
    10times 10 grid, 5 degree angle step, a=0.1 , b=0.6 , c=0.01 , u=6 and v=2 . As
    in [28], about 3 alignments were detected (2 in this example). Right: Result with
    a slightly different candidate set: 20times 20 grid and b=0.3 , producing 47 detections.
    A similar behavior is observed with sets of 1000 random points.'
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: "Jos\xE9 Lezama"
  Name of the last author: Rafael Grompone von Gioi
  Number of Figures: 16
  Number of Tables: 0
  Number of authors: 4
  Paper title: A Contrario 2D Point Alignment Detection
  Publication Date: 2014-08-05 00:00:00
  Table 1 caption:
    table_text: Not Available
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2345389
- Affiliation of the first author: department of computer science, nankai university,
    tianjin, china
  Affiliation of the last author: department of computer science and technology, tnlist,
    tsinghua university, beijing, china
  Figure 1 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_1.jpg
  Figure 1 caption: Given an input image (top), a global contrast analysis is used
    to compute a high resolution saliency map (middle), which can be used to produce
    an unsupervised segmentation mask (bottom) for an object of interest.
  Figure 10 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_10.jpg
  Figure 10 caption: From left to right, we show source image, ground truth eye fixation
    map by human observer, our RC result with the term encouraging similar appearance
    region receive similar saliency (Section 4.3 ) disabled, and result by our full
    RC method.
  Figure 2 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_2.jpg
  Figure 2 caption: Saliency maps computed by different state-of-the-art methods (b-p),
    and with our proposed HC (q) and RC methods (r). Most results highlight edges,
    or are of low resolution. See also Fig. 9 and our project webpage.
  Figure 3 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_3.jpg
  Figure 3 caption: Given an input image (left), we compute its color histogram (middle).
    Corresponding histogram bin colors are shown in the lower bar. The quantized image
    (right) uses only 43 histogram bin colors and still retains sufficient visual
    quality for saliency detection.
  Figure 4 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_4.jpg
  Figure 4 caption: Saliency of each color before (left) and after (right) color space
    smoothing. Corresponding saliency maps are shown in the respective insets.
  Figure 5 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_5.jpg
  Figure 5 caption: 'Region based contrast computation: (a) input image, (b) image
    regions generated by Felzenszwalb and Huttenlocher''s segmentation method [45],
    (c) region contrast without distance weighting and spatial prior ((5)), (d) region
    contrast with distance weighting, (e) region contrast further considering spatial
    prior ( (7)), (f) region contrast after improvement by border region estimation
    and color space smoothing, (g) using our SaliencyCut (Section 5), we get a high
    quality cut that is comparable to human labeled ground truth.'
  Figure 6 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_6.jpg
  Figure 6 caption: "Demonstration of SaliencyCut: (a) original image, (b) initial\
    \ segmentation by fixed thresholding the saliency map, (c) trimap after first\
    \ iteration, (d) trimap after second iteration, (e) final segmentation, and (f)\
    \ manually labeled ground truth. In the segmented images (e), blue is foreground,\
    \ gray is background, while in the trimaps (b\u2013d), foreground is red, background\
    \ is green, and unknown regions are left unchanged."
  Figure 7 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_7.jpg
  Figure 7 caption: Average time taken to compute a saliency map for images in the
    MSRA10K database (most have resolution 400times 300 ). We use parallel computing
    environment for all Matlab functions for efficient computation.
  Figure 8 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_8.jpg
  Figure 8 caption: 'Ground truth examples: (first row) original images with ground
    truth rectangles from [2], (second row) our ground truth, which have more precisely
    marked important regions at pixel level accuracy.'
  Figure 9 Link: articels_figures_by_rev_year\2014\Global_Contrast_Based_Salient_Region_Detection\figure_9.jpg
  Figure 9 caption: Visual comparison of saliency maps. (a) original images, saliency
    maps produced using (b) Zhai and Shah [34], (c) Goferman et al. [32], (d) Achanta
    et al. [33], (e) our HC and (f) RC methods, and (g) SaliencyCut. Our methods generate
    uniformly highlighted salient regions (see our project webpage for all results
    on the full benchmark dataset).
  First author gender probability: 0.75
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.98
  Name of the first author: Ming-Ming Cheng
  Name of the last author: Shi-Min Hu
  Number of Figures: 17
  Number of Tables: 0
  Number of authors: 5
  Paper title: Global Contrast Based Salient Region Detection
  Publication Date: 2014-08-05 00:00:00
  Table 1 caption:
    table_text: Not Available
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2345401
- Affiliation of the first author: department of applied mathematics, research school
    of physics and engineering, the australian national university, canberra, act,
    australia
  Affiliation of the last author: department of applied mathematics, research school
    of physics and engineering, the australian national university, canberra, act,
    australia
  Figure 1 Link: articels_figures_by_rev_year\2014\Skeletonization_and_Partitioning_of_Digital_Images_Using_Discrete_Morse_Theory\figure_1.jpg
  Figure 1 caption: In this example we build the lower star of vertex 8 in a cubical
    complex by incrementally adding simple-homotopy pairs when possible. (a) The vertices
    1-7 and six dark edges are present in the subcomplex mathcal K(7) ; the lower
    star of vertex 8 contains four edges and three square faces. (b) Vertex 8 is paired
    with the edge 81. (c) Edge 82 is added as a critical cell. (d) Edge 83 is paired
    with face 8432. (e) Edge 86 is paired with face 8653. (f) Face 8762 is added as
    a critical cell. This configuration of voxels represents a compound critical point
    for the (6, 26) digital topology; the addition of two critical cells accurately
    reflects the change in the topology of the level subcomplexes in going from mathcal
    K(7) to mathcal K(8) .
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Skeletonization_and_Partitioning_of_Digital_Images_Using_Discrete_Morse_Theory\figure_2.jpg
  Figure 2 caption: A 1D function with three minima alpha 1, alpha 2, alpha 3 and
    two maxima alpha 4, alpha 5 . The Morse complex of this function is analysed in
    the text. Persistent homology pairs alpha 4 with alpha 3 and alpha 5 with alpha
    2 .
  Figure 3 Link: articels_figures_by_rev_year\2014\Skeletonization_and_Partitioning_of_Digital_Images_Using_Discrete_Morse_Theory\figure_3.jpg
  Figure 3 caption: Execution times and memory consumption for some 3D images. Numbers
    of critical cells before and after simplification with persistence threshold 1
    are listed. Memory consumption and execution times are given for the gradient
    vector field computation, simplification, and Morse chain complex computation
    before and after simplification.
  Figure 4 Link: articels_figures_by_rev_year\2014\Skeletonization_and_Partitioning_of_Digital_Images_Using_Discrete_Morse_Theory\figure_4.jpg
  Figure 4 caption: Morse analysis of a 2D euclidean distance image (Mt. Gambier limestone).
    The solid phase (background) is shown in gray, and the void space (foreground)
    is divided into colored pores formed by its intersections with the basins. Critical
    cells are indicated by round dots, black for minima, cyan for saddles, and white
    for maxima. The Morse skeleton is shown in white, and other V-paths between critical
    cells in cyan.
  Figure 5 Link: articels_figures_by_rev_year\2014\Skeletonization_and_Partitioning_of_Digital_Images_Using_Discrete_Morse_Theory\figure_5.jpg
  Figure 5 caption: A sphere pack with the Morse skeleton of its pore space shown
    in blue. The blue patches are unstable complexes of persistent critical2-cells.
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.99
  Name of the first author: Olaf Delgado-Friedrichs
  Name of the last author: Adrian Sheppard
  Number of Figures: 5
  Number of Tables: 0
  Number of authors: 3
  Paper title: Skeletonization and Partitioning of Digital Images Using Discrete Morse
    Theory
  Publication Date: 2014-08-07 00:00:00
  Table 1 caption:
    table_text: Not Available
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2346172
- Affiliation of the first author: department of industrial and manufacturing engineering,
    florida state university, tallahassee, fl
  Affiliation of the last author: department of fundamental and computational sciences,
    pacific northwest national laboratory, richland, wa
  Figure 1 Link: articels_figures_by_rev_year\2014\Minimum_Cost_MultiWay_Data_Association_for_Optimizing_Multitarget_Tracking_of_In\figure_1.jpg
  Figure 1 caption: Cost function for exemplary two-way data associations.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Minimum_Cost_MultiWay_Data_Association_for_Optimizing_Multitarget_Tracking_of_In\figure_2.jpg
  Figure 2 caption: Sample snapshots of a simulated system of particles.
  Figure 3 Link: articels_figures_by_rev_year\2014\Minimum_Cost_MultiWay_Data_Association_for_Optimizing_Multitarget_Tracking_of_In\figure_3.jpg
  Figure 3 caption: Convergence of our Lagrange dual solution; all curves are rescaled
    to range from 0 to 1 in the vertical axis.
  Figure 4 Link: articels_figures_by_rev_year\2014\Minimum_Cost_MultiWay_Data_Association_for_Optimizing_Multitarget_Tracking_of_In\figure_4.jpg
  Figure 4 caption: Sample nanoparticle trajectories.
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.96
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Chiwoo Park
  Name of the last author: Nigel D. Browning
  Number of Figures: 4
  Number of Tables: 4
  Number of authors: 4
  Paper title: Minimum Cost Multi-Way Data Association for Optimizing Multitarget
    Tracking of Interacting Objects
  Publication Date: 2014-08-07 00:00:00
  Table 1 caption:
    table_text: "TABLE 1 Simulation Data\u2014Data Association Errors of Our Method\
      \ with M=2 and M=3 , Henriques' Method [31], Jaqaman's Method [28], and MCMC\
      \ Data Association [19]."
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: "TABLE 2 Real Microscope Data\u2014Data Association Errors of Our\
      \ Method with M=3 , Henriques' Method [31], Jaqaman's Method [28], and MCMC\
      \ Data Association [19]"
  Table 3 caption:
    table_text: "TABLE 3 PETS.S2.L1 Data\u2014Data Association Errors of Our Method\
      \ with M=3 , Henriques' Method [31], Jaqaman's Method [28], and MCMC Data Association\
      \ [19]"
  Table 4 caption:
    table_text: "TABLE 4 PETS.S2.L2 Data\u2014Data Association Errors of Our Method\
      \ with M=3 , Henriques' Method [31], Jaqaman's Method [28], and MCMC Data Association\
      \ [19]"
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2346202
- Affiliation of the first author: department of mechanical engineering, purdue university,
    west lafayette, in
  Affiliation of the last author: department of electrical and computer engineering,
    national university of singapore, singapore
  Figure 1 Link: articels_figures_by_rev_year\2014\Dense_Subgraph_Partition_of_Positive_Hypergraphs\figure_1.jpg
  Figure 1 caption: Dense subgraph partition of a weighted graph mathbf G and its
    relation to densest k -subgraphs. DSP has two layers of partition. In the first
    layer, mathbf G is partitioned into three ordered subgraphs, namely, mathbf GV1
    , mathbf GV2 and mathbf GV3 , ordered by their densities, from large to small.
    In the second layer, mathbf GV2 is partitioned into two pseudo-disjoint subgraphs,
    mathbf GV4 and mathbf GV5 , and mathbf GV3 is partitioned into two pseudo-disjoint
    subgraphs, mathbf GV6 and mathbf GV7 . Thus, the graph mathbf G has been partition
    into 5 ordered dense subgraphs by DSP, where mathbf GV4 and mathbf GV5 are exchangeable,
    as well as mathbf GV6 and mathbf GV7 . From DSP, we can easily get exact densest
    k -subgraphs for some k s, such as D 4 S, D 7 S, D 10 S and D 11 S for this graph.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Dense_Subgraph_Partition_of_Positive_Hypergraphs\figure_2.jpg
  Figure 2 caption: The process of min-partition for the graph in Fig. 1 under the
    permutation mathbf P . The inputs are the permutation mathbf P and corresponding
    reward vector rmathbf P , the output is the min-partition mboxMP(mathbf P) . Only
    one scan of the reward vector rmathbf P is needed.
  Figure 3 Link: articels_figures_by_rev_year\2014\Dense_Subgraph_Partition_of_Positive_Hypergraphs\figure_3.jpg
  Figure 3 caption: Illustration of an iteration of Alg. 1 (step 5 to step 15 ). First,
    apply permutation-reorder() on mathbf P2 to find a better one, hatmathbf P2 ,
    and apply min-partition() on hatmathbf P2 to get mboxMP(hatmathbf P2) . Replacing
    mathbf P2 by mboxMP(hatmathbf P2) , we get a partition of mathbf P , Omega =langle
    mathbf P1,mathbf K1,mathbf K2,mathbf P3rangle . Second, apply min-merge() on Omega
    to get mboxMP(hatmathbf P) .
  Figure 4 Link: articels_figures_by_rev_year\2014\Dense_Subgraph_Partition_of_Positive_Hypergraphs\figure_4.jpg
  Figure 4 caption: Illustrations of the statistics of subgraphs obtained by DSP.
  Figure 5 Link: articels_figures_by_rev_year\2014\Dense_Subgraph_Partition_of_Positive_Hypergraphs\figure_5.jpg
  Figure 5 caption: The results of D k S on 10 webgraphs. Feige's method is shown
    in green dotted curve, the truncated power method is shown in blue dashdot curve,
    and our method is shown in red solid curve. This figure is best viewed in color.
  Figure 6 Link: articels_figures_by_rev_year\2014\Dense_Subgraph_Partition_of_Positive_Hypergraphs\figure_6.jpg
  Figure 6 caption: (a) The Precision-Recall curve from a mathbf Pin Theta (mathbf
    G) , (b) the label distribution along mathbf P , where the label 11 representing
    outliers.
  Figure 7 Link: articels_figures_by_rev_year\2014\Dense_Subgraph_Partition_of_Positive_Hypergraphs\figure_7.jpg
  Figure 7 caption: The experimental results of image matching. The first column shows
    two images to be matched, there is a one-to-one matching (American Express), a
    one-to-two matching (MasterCard) and a two-to-one matching (Visa). The second,
    third, fourth, fifth and sixth column show the matching results of DSP, CG, TM,
    HGM and RRWHM, respectively. Green dots are interest points, lines represent correspondences.
    CG and our method can distinguish different matchings, therefore their correspondences
    in different matchings are shown in different colors; TM, HGM and RRWHM only detect
    correct correspondences, thus there correspondences are only shown in blue color.
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.57
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Hairong Liu
  Name of the last author: Shuicheng Yan
  Number of Figures: 7
  Number of Tables: 4
  Number of authors: 3
  Paper title: Dense Subgraph Partition of Positive Hypergraphs
  Publication Date: 2014-08-07 00:00:00
  Table 1 caption:
    table_text: TABLE 1 The Statistics of 10 Networks Used in Our Experiments
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 3 Result of Cluster Detection on Handwritten Dataset
  Table 3 caption:
    table_text: TABLE 2 Statistics of DSP on 10 Networks
  Table 4 caption:
    table_text: TABLE 4 Performances in the Image Matching Experiments
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2346173
- Affiliation of the first author: pillar of information systems technology and design,
    singapore university of technology and design, singapore
  Affiliation of the last author: department of mathematics, university of california,
    los angeles, ca
  Figure 1 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_1.jpg
  Figure 1 caption: Six images showing a typical input (example Fish).
  Figure 10 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_10.jpg
  Figure 10 caption: (a) A dual-layered graph cal G = langle V,Erangle is built where
    each pixel has two nodes. cal V is the set of all nodes representing the clustered
    normals, cal E is the set of all edges connecting adjacent nodes. (b) For pixels
    with only one cluster, one can duplicate the cluster to simplify the implementation.
    The final graph can have up to 2N nodes for N processing pixels. Every node can
    have up to nine edges connected to their neighboring nodes. Pixel locations with
    no observation will be completed by their initial estimation.
  Figure 2 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_2.jpg
  Figure 2 caption: Our budget setup. The spotlight is moved around to simulate a
    distant light source with constant radiance. The video camera is an off-the-shelf
    DV of limited dynamic range (Nikon D40). The transparent object and the reference
    chrome sphere are captured at the same time.
  Figure 3 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_3.jpg
  Figure 3 caption: Orientation consistency in the presence of transparency and indirect
    illumination effects. The reference sphere and the object have different material
    properties but they act like ideal specular objects when they reflect specular
    highlights (brightness and contrast were enhanced for visualization).
  Figure 4 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_4.jpg
  Figure 4 caption: Under the orthographic camera assumption, we can directly obtain
    the normal orientation from the reference sphere. Notice that given a single view,
    only a subset of normals can be computed. ( L is light direction, R reflection
    direction, N is normal direction.)
  Figure 5 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_5.jpg
  Figure 5 caption: Three typical scenarios on the observed light emanating from a
    point on the exterior surface of a transparent and refractive object. The numbers
    in the figure indicate intensity magnitudes. Orientation consistency should be
    applied to (a), but not to (b) or (c) because they are not specular reflections.
    Truefalse highlights can be marked easily.
  Figure 6 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_6.jpg
  Figure 6 caption: The normal clusters at selected pixels over time.
  Figure 7 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_7.jpg
  Figure 7 caption: User can select the regions for direct (green circles) or indirect
    highlights (blue circles). Pixels within the region with intensity higher than
    threshold will be labeled accordingly.
  Figure 8 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_8.jpg
  Figure 8 caption: For every pixel location, we cluster the transferred normals into
    two salient clusters given the T image frames by their intensity.
  Figure 9 Link: articels_figures_by_rev_year\2014\Normal_Estimation_of_a_Transparent_Object_Using_a_Video\figure_9.jpg
  Figure 9 caption: '[color figure] Color map showing the number of clusters for each
    example. Gray: No cluster. Blue: 1 cluster. Purple: 2 clusters. White: more than
    2 clusters. Refer to the text for cluster formation.'
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Sai-Kit Yeung
  Name of the last author: Stanley J. Osher
  Number of Figures: 15
  Number of Tables: 6
  Number of authors: 5
  Paper title: Normal Estimation of a Transparent Object Using a Video
  Publication Date: 2014-08-07 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Analogy of Our Problem to Image Segmentation (e.g., [16],
      [26])
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Summary of the Notations in This Paper
  Table 3 caption:
    table_text: TABLE 3 Node Values at a Given Pixel (i and j Are the Pixel's Neighboring
      Nodes in the TopBottom Layers Shown in Fig. 10)
  Table 4 caption:
    table_text: TABLE 4 Hard Constraints for Estimating the Surface Normals at Different
      Stages
  Table 5 caption:
    table_text: TABLE 5 Running Times Are Measured on a Desktop Computer with Dual-Core
      2.6 GHz CPU and 3.0 GB RAM
  Table 6 caption:
    table_text: TABLE 6 The Mean Errors of the Computed Surface Normals Using Our
      Method and [7] Are Shown (Where the Error Is Defined as Sum of the Squared Difference
      of Three Normal Components)
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2346195
