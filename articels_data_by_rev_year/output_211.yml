- Affiliation of the first author: department of statistics and the department of
    electrical engineering and computer sciences, university of california, berkeley,
    ca
  Affiliation of the last author: department of statistics and the department of electrical
    engineering and computer sciences, university of california, berkeley, ca
  Figure 1 Link: articels_figures_by_rev_year\2014\Combinatorial_Clustering_and_the_Beta_Negative_Binomial_Process\figure_1.jpg
  Figure 1 caption: For each r evenly spaced between 1 and 1,001, we simulate (random)
    values of the number of data points N and number of clusters K from the rm BNBP
    and rm 3BNBP . In both plots, we have mass parameter gamma =3 and concentration
    parameter theta =3 . On the left, we see the number of clusters K as a function
    of the negative binomial parameter r (see Lemma 12 and Lemma 13 in Appendix C,
    available in the online supplemental material); on the right, we see the number
    of clusters K as a function of the (random) number of data points N (see Theorem
    16 and Theorem 17 in Appendix C, available in the online supplemental material).
    In both plots, the upper black points show simulation results for the case alpha
    =0.5 , and the lower blue points show alpha =0 . Red lines indicate the theoretical
    asymptotic mean behavior we expect from Section 5.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Combinatorial_Clustering_and_the_Beta_Negative_Binomial_Process\figure_2.jpg
  Figure 2 caption: "Number of admixture components used by the finite approximation\
    \ sampler with K=100 ( left) and the exact Gibbs slice sampler (right) on each\
    \ iteration of rm HBNBP admixture model posterior inference. We use a standard\
    \ \u201Ctoy bars\u201D data set with 10 underlying admixture components (cf. [15]).\
    \ We declare a component to be used by a sample if the sampled beta process weight,\
    \ b0,k , exceeds a small threshold. Both the exact and the finite approximation\
    \ sampler find the correct underlying structure, while the finite sampler attempts\
    \ to innovate more because of the larger number of proposal components available\
    \ to the data in each iteration."
  Figure 3 Link: articels_figures_by_rev_year\2014\Combinatorial_Clustering_and_the_Beta_Negative_Binomial_Process\figure_3.jpg
  Figure 3 caption: Document length distributions and word frequencies for each organization
    in the WITS perpertrator identification experiment.
  Figure 4 Link: articels_figures_by_rev_year\2014\Combinatorial_Clustering_and_the_Beta_Negative_Binomial_Process\figure_4.jpg
  Figure 4 caption: MSRC-v1 test image segmentations inferred by the HBNBP admixture
    model (best viewed in color).
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 1.0
  Gender of the first author: female
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Tamara Broderick
  Name of the last author: Michael I. Jordan
  Number of Figures: 4
  Number of Tables: 6
  Number of authors: 4
  Paper title: Combinatorial Clustering and the Beta Negative Binomial Process
  Publication Date: 2014-04-18 00:00:00
  Table 1 caption:
    table_text: "TABLE 1 Let N Be the Number of Data Points When This Number Is Fixed\
      \ and \u03BE(r) Be the Expected Number of Data Points When N Is Random"
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 The Number of Incidents Claimed by Each Organization in the
      WITS Perpetrator Identification Experiment
  Table 3 caption:
    table_text: TABLE 3 Confusion Matrices for WITS Perpetrator Identification
  Table 4 caption:
    table_text: TABLE 4 The 10 Most Probable Words from the Most Probable Topic in
      the Final MCMC Sample of Each Group in the WITS Perpetrator Identification Experiment.
  Table 5 caption:
    table_text: TABLE 5 Confusion Matrices for Patch-Level Image Segmentation and
      Object Recognition on the MSRC-v1 Database
  Table 6 caption:
    table_text: TABLE 6 Sensitivity of HBNBP Admixture Model to Hyperparameter Specification
      for Joint Image Segmentation and Object Recognition on the MSRC-v1 Database
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2318721
- Affiliation of the first author: twitter inc., san francisco, ca
  Affiliation of the last author: department of mathematics, duke university, durham,
    nc
  Figure 1 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_1.jpg
  Figure 1 caption: Depicting the observations extracted (e.g., image patches) from
    high and low resolution images.
  Figure 10 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_10.jpg
  Figure 10 caption: (Baby) Test set results with SR ratio = 4.
  Figure 2 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_2.jpg
  Figure 2 caption: Graphical model.
  Figure 3 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_3.jpg
  Figure 3 caption: Dictionary trained in batch mode on lluminance channel with SR
    ratio = 2 . (Top) HR Dictionary, (Bottom) LR Dictionary. Every square represents
    a dictionary element and the HR-LR pairs are co-located. HR dictionary consists
    of sharper edges.
  Figure 4 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_4.jpg
  Figure 4 caption: Human evaluation via mechanical turk. (Top) Average win rate in
    one-to-one comparisons. (Bottom) Win rates for each one-to-one comparison. Each
    number represents the winning rate of the method in the column, e.g., 0.57 for
    BP versus ScSR (BP is on the column and ScSR on the row) means that on average,
    0.57 of the times Turkers voted in favor of BP.
  Figure 5 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_5.jpg
  Figure 5 caption: 'Reconstruction of natural image 3. BP: Algorithm presented in
    this work trained via Gibbs sampler, O-BP Algorithm presented in this work trained
    via Online VB, ScSR: Super-Resolution via Sparse Representation. Example based
    approaches are superior to interpolation techniques, ScSR and our approach perform
    similarly.'
  Figure 6 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_6.jpg
  Figure 6 caption: 'Reconstruction of Parthenon image. BP: Algorithm presented in
    this work trained via Gibbs sampler, O-BP Algorithm presented in this work trained
    via Online VB, ScSR: Super-Resolution via Sparse Representation. SME: Sparse Mixing
    Estimation [45].'
  Figure 7 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_7.jpg
  Figure 7 caption: Learning the number of dictionary elements from the data. (Top)
    PSNR of the reconstruction of the Barbara image by nonparametric BP and parametric
    ScSR with different number of dictionary elements. (Bottom) Histogram of the number
    of dictionary elements for BP when K=1,024 over 100 samples.
  Figure 8 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_8.jpg
  Figure 8 caption: Held-out prediction performances of online learning with different
    mini-batch sizes. Online-VB run on the whole data set is compared with the Batch-VB
    run on a subset of the data. The online algorithms converge much faster than the
    batch algorithm does.
  Figure 9 Link: articels_figures_by_rev_year\2014\A_Bayesian_Nonparametric_Approach_to_Image_SuperResolution\figure_9.jpg
  Figure 9 caption: (Natural image 18) test results, SR ratio = 4.
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: female
  Last author gender probability: 1.0
  Name of the first author: "G\xFCng\xF6r Polatkan"
  Name of the last author: Ingrid Daubechies
  Number of Figures: 10
  Number of Tables: 2
  Number of authors: 5
  Paper title: A Bayesian Nonparametric Approach to Image Super-Resolution
  Publication Date: 2014-05-01 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Test Results with SR Ratio =2
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Test Results on Natural Images with SR Ratio = 2
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2321404
- Affiliation of the first author: department of brain and cognitive sciences, massachusetts
    institute of technology, cambridge, ma
  Affiliation of the last author: department of computer science, princeton university,
    35 olden street, princeton, nj
  Figure 1 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_1.jpg
  Figure 1 caption: Schematic of the IBP. An example of a latent feature matrix (
    bf Z ) generated by the IBP. Rows correspond to customers (data points) and columns
    correspond to dishes (features). Gray shading indicates that a feature is active
    for a given data point. The last row illustrates the assignment process for a
    new customer; the counts for each feature ( mik ) are shown inside the circles
    for previously sampled features.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_2.jpg
  Figure 2 caption: "Schematic of the dd-IBP. An example of a latent feature matrix\
    \ generated by the dd-IBP. Rows correspond to customers (data points) and columns\
    \ correspond to dishes (features). Customers connect to each other, as indicated\
    \ by arrows. Customers inherit a dish if the owner of that dish ( c \u2217 k ,\
    \ indicated by stars) is reachable by a sequence of connections. Gray shading\
    \ indicates that a feature is active for a given data point."
  Figure 3 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_3.jpg
  Figure 3 caption: Decay functions. Each panel presents a different latent feature
    matrix, sampled from the dd-IBP with sequential distances. Decay functions are
    shown in the insets.
  Figure 4 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_4.jpg
  Figure 4 caption: 'Feature-sharing in the dHBP and dd-IBP, limiting case. Along
    the horizontal axis, we show four independent draws from the dHBP (Top) and dd-IBP
    (Bottom). Within each subfigure, the shade of a cell (i,j) shows the fraction
    RijRi , where Ri is the number of features held by data point i , and Rij is the
    number held by both i and j . Diagonals RiiRi = 1 have been set to 0 for clarity.
    Here, alpha =gamma =1,000 . Limiting results from Section 4 explain the behavior
    for such large alpha and gamma : for the dHBP the feature-sharing proportion RijRi
    is random and equal to one of two constants; for the dd-IBP the proportion is
    non-random and takes a range of values. The dd-IBP models feature-sharing proportions
    that differ across data points, but does not model uncertainty about these proportions
    when mass parameters are large.'
  Figure 5 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_5.jpg
  Figure 5 caption: Feature-sharing in the dHBP and dd-IBP. Heatmaps of the probability
    mass function over the number of shared features Rij (y-axis) as a function of
    proximity aij (x -axis) in a data set consisting of two data points. Black indicates
    a probability mass of 0, with lighter shades indicating larger values. For the
    dHBP, we set c0=10 and c1=1 . Note that bb E[Ri] is the same for both the dHBP
    and dd-IBP in these examples (when alpha =gamma ).
  Figure 6 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_6.jpg
  Figure 6 caption: Linear-Gaussian model. Matrix multiplication view of how latent
    features ( bf Z ) combine with a weight matrix ( bf W ) and white noise ( epsilon
    ) to produce observed data ( bf X ).
  Figure 7 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_7.jpg
  Figure 7 caption: Trace plots. Representative traces of the log joint probability
    of the Alzheimer's data and latent variables for the dd-IBP (top) and dHBP (bottom).
    Each iteration corresponds to a sweep over all the latent variables.
  Figure 8 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_8.jpg
  Figure 8 caption: Inferred latent features for the Alzheimer's data set. Hinton
    diagram showing the posterior expected latent feature matrix. Rows correspond
    to data points (ordered according to increasing age), columns correspond to latent
    features. The size of the square indicates the magnitude of the corresponding
    entry.
  Figure 9 Link: articels_figures_by_rev_year\2014\Distance_Dependent_Infinite_Latent_Feature_Models\figure_9.jpg
  Figure 9 caption: "Classification results for the Alzheimer's data set. Area under\
    \ the curve (AUC) for binary classification (Alzheimer's versus normal control)\
    \ using L2 -regularized logistic regression and features learned from a linear-Gaussian\
    \ latent feature model. Each curve represents a different choice of predictor\
    \ variables (latent features) for logistic regression. The x-axis corresponds\
    \ to different settings of the exponential decay function parameter, beta . \u201C\
    Raw\u201D refers to the original data features (see text for details); the IBP,\
    \ dd-IBP, dIBP and dHBP results were based on using the latent features of the\
    \ maximum a posteriori sample following 1,500 iterations of MCMC sampling. Error\
    \ bars represent standard error of the mean."
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Samuel J. Gershman
  Name of the last author: David M. Blei
  Number of Figures: 9
  Number of Tables: 0
  Number of authors: 3
  Paper title: Distance Dependent Infinite Latent Feature Models
  Publication Date: 2014-05-01 00:00:00
  Table 1 caption:
    table_text: Not Available
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2321387
- Affiliation of the first author: university of cambridge, cambridge, england, united
    kingdom
  Affiliation of the last author: university of cambridge, cambridge, england, united
    kingdom
  Figure 1 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_1.jpg
  Figure 1 caption: 'An illustrative example of the structure modelled by ILA which
    explains the friendship network at Hogwarts school. Left: each student at Hogwarts
    has the ''house'' feature, and belongs to one of three subclusters (houses): Gryffindor,
    Ravenclaw or Slytherin. These subclusters are disjoint. Students within a house
    are very likely (0.8) to be friends. Students from Gryffindor are sometimes friends
    with Ravenclaws (0.2), but Slytherins are never friends with either of the other
    houses. Middle: a second feature with only one subcluster is membership of Dumbledore''s
    Army, which contains Ravenclaws and Gryffindors, and has an even higher probability
    (0.9) of resulting in a friendship link than being a member of the same house.
    Right: the final friendship network is an element-wise OR of the links resulting
    from either of the two features (see Section 2.1).'
  Figure 10 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_10.jpg
  Figure 10 caption: A subnetwork of the cancer cell map with high disassociavity.
    These nodes belong to two subclusters of a particularly active four subcluster
    feature.
  Figure 2 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_2.jpg
  Figure 2 caption: Diagram of the ILA model. bf ci and bf cj are the subcluster assignments
    for objects i and j respectively, shown here with M=3 features. ci(2) being zero
    corresponds to the absence of feature 2 for object i , so this feature contributes
    no weight. For the two features which are active for both i and j , namely features
    1 and 3 , the subcluster assignments dictate which element of the feature's weight
    matrix should be chosen for each feature. Finally the weights are summed and passed
    through a sigmoid function to give the probability of a link between i and j .
  Figure 3 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_3.jpg
  Figure 3 caption: 'Synthetic data example. (a) Observed synthetic 30 times 30 link
    matrix. White corresponds to zero, black to one. (b) ILA (logistic) solution.
    Contribution to the adjacency matrix from the two features found, the first has
    three subclusters, and the second two dis-associative subclusters. (c) LFRM solution:
    bf Z matrix. White corresponds to zero, black to one (active feature). (d) IRM
    solution. Six clusters are found.'
  Figure 4 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_4.jpg
  Figure 4 caption: Predictions for the three models on the NIPS 1-17 coauthorship
    data set. In (a), white denotes that two people wrote a paper together, while
    in (b), (c), and (d), the lighter the entry, the more confident the model is that
    the corresponding authors would collaborate.
  Figure 5 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_5.jpg
  Figure 5 caption: Average test error as a function of MCMC iteration on the NIPS
    data set. Because of sequential initialisation even at iteration 1 much of the
    predictive performance has already been achieved.
  Figure 6 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_6.jpg
  Figure 6 caption: Average test error as a function of time on the NIPS data set.
    While ILA has a higher per iteration cost than the IRM or LFRM we see that ILA
    would still perform best even given the same computation budget.
  Figure 7 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_7.jpg
  Figure 7 caption: Predictive performance (top) and model complexity (bottom) for
    varying amounts of training data on the NIPS data set. Points shown are averages
    from three repeats. Complexity is number of clusters for IRM, number of features
    for LFRM and total number of subclusters across all features for ILA (noisy-OR).
  Figure 8 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_8.jpg
  Figure 8 caption: Predictions for the three models on the gene interaction network
    data set. In (a), white denotes that two genes interact, while in (b), (c), and
    (d), the lighter the entry, the more confident the model is that the corresponding
    genes would interact. Note that a lot more of the structure in the data is captured
    by ILA.
  Figure 9 Link: articels_figures_by_rev_year\2014\Relational_Learning_and_Network_Modelling_Using_Infinite_Latent_Attribute_Models\figure_9.jpg
  Figure 9 caption: The proportion of clusters (IRM), features (LFRM) or subclusters
    (ILA) with a significant association to a Gene Ontology term across 10 repeats.
    ILA finds more meaningful groups of genes than IRM or LFRM.
  First author gender probability: 1.0
  Gender of the first author: female
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Konstantina Palla
  Name of the last author: Zoubin Ghahramani
  Number of Figures: 15
  Number of Tables: 2
  Number of authors: 3
  Paper title: Relational Learning and Network Modelling Using Infinite Latent Attribute
    Models
  Publication Date: 2014-05-16 00:00:00
  Table 1 caption:
    table_text: TABLE 1 NIPS Coauthorship Network Results
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Gene Interaction Network Results
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2324586
- Affiliation of the first author: school of automation science and engineering, south
    china university of technology, guangzhou, china
  Affiliation of the last author: department of biomedical engineering, tsinghua university,
    beijing, china
  Figure 1 Link: articels_figures_by_rev_year\2014\Probabilistic_Common_Spatial_Patterns_for_Multichannel_EEG_Analysis\figure_1.jpg
  Figure 1 caption: P-CSP modeling framework. The models and algorithms proposed in
    this paper are based on a probabilistic modeling reformulation of the CSP algorithm.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Probabilistic_Common_Spatial_Patterns_for_Multichannel_EEG_Analysis\figure_2.jpg
  Figure 2 caption: Effective component number Me determined by VB-CSP under different
    settings of L and SNR.
  Figure 3 Link: articels_figures_by_rev_year\2014\Probabilistic_Common_Spatial_Patterns_for_Multichannel_EEG_Analysis\figure_3.jpg
  Figure 3 caption: 'The average Amari indices obtained under varying SNRs and sample
    sizes. left panel: L=500 ; right panel: L=100 .'
  Figure 4 Link: articels_figures_by_rev_year\2014\Probabilistic_Common_Spatial_Patterns_for_Multichannel_EEG_Analysis\figure_4.jpg
  Figure 4 caption: 'Hinton diagrams of mathbf A and hatmathbf A estimated by different
    algorithms for an exemplary run with L=500 and texttt ttSNR=0;mathrmrm dB (columns
    are in random order). The magnitude of each entry in the matrices is proportional
    to the square size (dark: positive, light: negative). Note that the results are
    subject to the scaling and permutation ambiguities. a) Non-square mixing matrix
    mathbf A , b) Estimated square matrix hatmathbf A from CSP ( D=1.3332 ), c) Estimated
    non-square matrix hatmathbf A from MAP-CSP ( D=0.5094 ), d) Estimated sparse matrix
    hatmathbf A from VB-CSP ( D=0.3239 ).'
  Figure 5 Link: articels_figures_by_rev_year\2014\Probabilistic_Common_Spatial_Patterns_for_Multichannel_EEG_Analysis\figure_5.jpg
  Figure 5 caption: Examples of convergence curves of tildemathcal F , hatmathbf A
    , and hatmathbf Zk at L=100 .
  Figure 6 Link: articels_figures_by_rev_year\2014\Probabilistic_Common_Spatial_Patterns_for_Multichannel_EEG_Analysis\figure_6.jpg
  Figure 6 caption: Test errors (percent) on three motor imagery BCI data sets ( 43
    subsets) for four tested algorithms. Each point provides the result on one subset
    of EEG data. a) VB-CSP versus CSP, b) VB-CSP versus TR-CSP, c) MAP-CSP versus
    CSP, d) MAP-CSP versus TR-CSP, e) TR-CSP versus CSP, f) VB-CSP versus MAP-CSP.
  Figure 7 Link: articels_figures_by_rev_year\2014\Probabilistic_Common_Spatial_Patterns_for_Multichannel_EEG_Analysis\figure_7.jpg
  Figure 7 caption: 'Hinton diagrams of the estimated sparse matrix hatmathbf A (columns
    are in random order). Upper panel: the variational mean estimates from VB-CSP;
    lower panel: the estimates from CSP. a) subject s1 , b) subject s2 .'
  Figure 8 Link: articels_figures_by_rev_year\2014\Probabilistic_Common_Spatial_Patterns_for_Multichannel_EEG_Analysis\figure_8.jpg
  Figure 8 caption: 'The spatio-temporal patterns of selected two meaningful components.
    For each subject, the left panel presents the ERPs of the components (dark curves:
    variational means; light curves: 95 percent posterior credible intervals), and
    the right panel presents the spatial patterns of the components as scalp maps.
    a) subject s1 , b) subject s2 .'
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.73
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Wei Wu
  Name of the last author: Shangkai Gao
  Number of Figures: 8
  Number of Tables: 2
  Number of authors: 6
  Paper title: Probabilistic Common Spatial Patterns for Multichannel EEG Analysis
  Publication Date: 2014-06-12 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Comparison of the Runtime (Second) from CSP, MAP-CSP and VB-CSP
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Comparison of the Test Errors (Percent) from Four Algorithms
      on Two Publicly Available Data Sets from BCI Competition 3
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2330598
- Affiliation of the first author: department of statistics, columbia university,
    new york, ny
  Affiliation of the last author: department of engineering, university of cambridge,
    cambridge cb2 3ap, united kingdom
  Figure 1 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_1.jpg
  Figure 1 caption: Sampling from a paint-box distribution with parameter mathbf s=(s1,s2,ldots,)
    . Two numbers i,j are assigned to the same block of the partition if the uniform
    variables Ui and Uj are contained in the same interval.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_2.jpg
  Figure 2 caption: "Exchangeable continuous-time processes: Shown on the left is\
    \ a sample path of a process X started at X0=0 . We define two intervals of equal\
    \ length, I1:=(0,t] and I2:=(t,2t] . A permuted path is obtained by swapping both\
    \ the intervals and the respective path segment of the process on each interval.\
    \ The path segments are shifted vertically such that the path starts again at\
    \ 0 and is \u201Dglued together\u201D at the interval boundary. If X is exchangeable,\
    \ the permuted process defined by permuting paths in this manner has the same\
    \ distribution as X ."
  Figure 3 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_3.jpg
  Figure 3 caption: 'de Finetti''s theorem expressed in terms of random functions:
    If F is the inverse CDF of the random measure Theta in the de Finetti representation,
    Xi can be generated as Xi:=F(Ui) , where Uisim mboxrm Uniform[0,1] .'
  Figure 4 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_4.jpg
  Figure 4 caption: "Sampling an exchangeable random graph according to Eq. (3.8)\
    \ . Left: A heat-map visualization of the random function W on [0,1]2 , given\
    \ here by W(x,y)=min lbrace x,yrbrace . Darker shades represent larger values.\
    \ In the case depicted here, the edge lbrace 1,2rbrace is not present in the graph,\
    \ because Ulbrace 1,2 rbrace >W(U1,U2) . Middle: The adjacency matrix of a 50-vertex\
    \ random graph, sampled from the function on the left. Rows (and columns) in the\
    \ matrix have been ordered by their underlying Ui value, resulting in a matrix\
    \ resembling W . Right: A plot of the random graph sample. The highly connected\
    \ vertices plotted in the center correspond to values lower right region in [0,1]2\
    \ . The minimum function example, due to Lov\xE1sz [47], is chosen as a particularly\
    \ simple symmetric function which is not piece-wise constant. See Section 4 for\
    \ examples with more structure."
  Figure 5 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_5.jpg
  Figure 5 caption: 'Non-uniqueness of representations: The function on the left parametrizes
    a random graph as in Fig. 4. On the right, this function has been modified by
    dividing the unit square into 10times 10 blocks and applying the same permutation
    of the set lbrace 1,ldots,,10rbrace simultaneously to rows and columns. Since
    the random variables Ui in Eq. (3.8) are i.i.d., sampling from either function
    defines one and the same distribution on random graphs.'
  Figure 6 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_6.jpg
  Figure 6 caption: 'Two examples of graphons for which monotonization does not yield
    a unique representation. Upper row: The functions w and wprime are distinct but
    parametrize the same random graph. For both, the projection v(x) (see Remark 3.8)
    is the constant function with value frac12 , which means both remain invariant
    and hence distinct under monotonization. Additionally, wprime prime also projects
    to v(x)=frac12 , but parametrizes a different random graph, i.e., projections
    do not distinguish different random graphs. Lower row: Another different example,
    where again w and wprime are equivalent to each other, but not to wprime prime
    . All three functions project to v(x)=frac13 .'
  Figure 7 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_7.jpg
  Figure 7 caption: "Typical directing random functions underlying, from left to right,\
    \ 1) an IRM (where partitions correspond with a Chinese restaurant process) with\
    \ conditionally i.i.d. link probabilities; 2) a more flexible variant of the IRM\
    \ with merely exchangeable link probabilities as in Example 4.3 ; 3) a LFRM (where\
    \ partitions correspond with an Indian buffet process) with feature-exchangeable\
    \ link probabilities as in Example 4.10; 4) a Mondrian-process-based model with\
    \ a single latent dimension; 5) a Gaussian-processed-based model with a single\
    \ latent dimension. In the first four figures, we have truncated each of the \u201C\
    stick-breaking\u201D constructions at a finite depth."
  Figure 8 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_8.jpg
  Figure 8 caption: 'For graph-valued data, the directing random function F in the
    Aldous-Hoover representation can be regarded as a limit of adjacency matrices:
    The adjacency matrix of a graph of size n can be represented as a function on
    [0,1]2 by dividing the square into ntimes n patches of equal size. On each patch,
    the representing function is constant, with value equal to the corresponding entry
    of the adjacency matrix. (In the figure, a black patch indicates a value of one
    and hence the presence of an edge.) As the size of the graph increases, the subdivision
    becomes finer, and converges to the function depicted on the right for nrightarrow
    infty . Convergence is illustrated here for the two functions from Fig. 5. Since
    the functions are equivalent, the two random graphs within each column are equal
    in distribution.'
  Figure 9 Link: articels_figures_by_rev_year\2014\Bayesian_Models_of_Graphs_Arrays_and_Other_Exchangeable_Random_Structures\figure_9.jpg
  Figure 9 caption: "If mathcal E is finite, the de Finetti mixture representation\
    \ Eq. (2.3) and the more general representation Eq. (7.1) reduce to a finite convex\
    \ combination. The points inside the set\u2014i.e., the distributions P with the\
    \ symmetry property defined by the group mathbb G \u2014can be represented as\
    \ convex combinations P=sum eiin mathcal Enu i ei , with coefficients nu ige 0\
    \ satisfying sum inu i=1 . When mathcal E is infinite, an integral is substituted\
    \ for the sum."
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Peter Orbanz
  Name of the last author: Daniel M. Roy
  Number of Figures: 9
  Number of Tables: 2
  Number of authors: 2
  Paper title: Bayesian Models of Graphs, Arrays and Other Exchangeable Random Structures
  Publication Date: 2014-07-01 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Exchangeable Random Structures
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Important Classes of Exchangeable Array Models, Categorized
      According to the Type Random FunctionParametrizing the Model (Where P.W.C. Stands
      for Piece-Wise Constant)
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2334607
- Affiliation of the first author: the key laboratory of computer network and information
    integration (southeast university), ministry of education, china
  Affiliation of the last author: the key laboratory of computer network and information
    integration (southeast university), ministry of education, china
  Figure 1 Link: articels_figures_by_rev_year\2014\Lift_MultiLabel_Learning_with_LabelSpecific_Features\figure_1.jpg
  Figure 1 caption: Comparison of Lift (control algorithm) against other comparing
    algorithms with the Bonferroni-Dunn test. Algorithms not connected with Lift in
    the CD diagram are considered to have significantly different performance from
    the control algorithm (significance level alpha =0.05 ).
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2014\Lift_MultiLabel_Learning_with_LabelSpecific_Features\figure_2.jpg
  Figure 2 caption: Performance of Lift changes in terms of each evaluation metric
    (mean pm std. deviation) as the ratio parameter r increases from 0.01 to 0.5 on
    four benchmark multi-label data sets.
  Figure 3 Link: Not Available
  Figure 3 caption: Not Available
  Figure 4 Link: Not Available
  Figure 4 caption: Not Available
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.63
  Gender of the first author: male
  Gender of the last author: female
  Last author gender probability: 0.55
  Name of the first author: Min-Ling Zhang
  Name of the last author: Lei Wu
  Number of Figures: 2
  Number of Tables: 9
  Number of authors: 2
  Paper title: 'Lift: Multi-Label Learning with Label-Specific Features'
  Publication Date: 2014-07-16 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Pseudo-Code of Lift
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Characteristics of the Experimental Data Sets
  Table 3 caption:
    table_text: "TABLE 3 Predictive Performance of Each Comparing Algorithm (mean\
      \ \xB1 std. Deviation) on the Eight Regular-Scale Data Sets"
  Table 4 caption:
    table_text: "TABLE 4 Predictive Performance of Each Comparing Algorithm (mean\
      \ \xB1 std. Deviation) on the Nine Large-Scale Data Sets"
  Table 5 caption:
    table_text: 'TABLE 5 Summary of the Friedman Statistics F F ( k=5 , N=17 ) and
      the Critical Value in Terms of Each Evaluation Metric ( k : Comparing Algorithms;
      N : Data Sets)'
  Table 6 caption:
    table_text: "TABLE 6 Predictive Performance of Lifted Versions of Clr and Ecc\
      \ (mean \xB1 std. Deviation) on Regular-Scale (Upper Part) and Large-Scale (Lower\
      \ Part) Data Sets"
  Table 7 caption:
    table_text: "TABLE 7 Wilcoxon Signed-Ranks Test for Br, Clr and Ecc against Their\
      \ Lifted Versions in Terms of EachEvaluation Metric (Significance Level \u03B1\
      =0.05 ; p -Values Shown in the Brackets)"
  Table 8 caption:
    table_text: "TABLE 8 Execution Time of Each Comparing Algorithm (mean \xB1 std.\
      \ Deviation) on Four Benchmark Multi-Label Data Sets"
  Table 9 caption:
    table_text: "TABLE 9 Wilcoxon Signed-Ranks Test for Lift against Lift-Ig, Lift-Mlf\
      \ and Mlls in Terms of Each Evaluation Metric(Significance Level \u03B1=0.05\
      \ ; p -Values Shown in the Brackets)"
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2339815
- Affiliation of the first author: department of computing, the hong kong polytechnic
    university, kowloon, hong kong
  Affiliation of the last author: department of computing, the hong kong polytechnic
    university, kowloon, hong kong
  Figure 1 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_1.jpg
  Figure 1 caption: Block diagram of the developed 3D fingerprint identification system
    with key modules.
  Figure 10 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_10.jpg
  Figure 10 caption: The receiver operating characteristics for the (a) relativecomparative
    performance using reconstructed 3D fingerprint images, and (b) performance using
    combination of 3D fingerprint and 2D fingerprint images acquired during photometric
    stereo based reconstruction.
  Figure 2 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_2.jpg
  Figure 2 caption: Reconstructed 3D fingerprint image illustrating (a) extended minutiae
    feature information in 3D space and (b) surface curvature from a typical fingerprint
    image.
  Figure 3 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_3.jpg
  Figure 3 caption: Using 2D minutia direction (purple arrow) defines the local ridge
    surface (blue dot) to estimate the 3D minutia direction (red arrow).
  Figure 4 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_4.jpg
  Figure 4 caption: "Relative localization of a 3D minutiae with a reference minutiae\
    \ (mr) in a given 3D fingerprint template using graphical illustration of relative\
    \ distancesangles between the reference 3D minutia ( mr) and other 3D minutia\
    \ (m). The x axis of Cartesian coordinate is aligned with the direction of mr\
    \ (the bold arrow). The azimuthal angles As and A\u03B8 are in the range of [0,\
    \ 360] degree. The polar angles Ag and A\u03C6 are in the range of [\u221290,\
    \ 90] degree. It may be noted that the magnitudevalue of (r, A s, A\u03B8, Ag,\
    \ A\u03C6 ) are exaggerated simply to illustrate these values clearly (rather\
    \ than use exact from left hand size image) and most of the finger surface is\
    \ convex. In the left figure, the green line for m illustrates orientation of\
    \ 3D minutiae while the red line illustrates its projection in x-y plane."
  Figure 5 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_5.jpg
  Figure 5 caption: Matching two genuine 3D minutia templates in (a) and the imposter
    templates in (b) from template P (in red color) and template Q (in blue color).
    The color lines are links from the reference minutia while the black lines illustrate
    the minutiae pairs that are regarded as matched.
  Figure 6 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_6.jpg
  Figure 6 caption: The location of minutiae (endpoint or bifurcation), from a sample
    clients 2D fingerprint images under different illuminations, with lighting (cross)
    and the clustered location (circle).
  Figure 7 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_7.jpg
  Figure 7 caption: (a) Typical image sample from the 2D fingerprint image of different
    clients, (b) image after image normalization, (c) corresponding enhanced images,
    (d) respective 3D surface curvature image and (e) reconstructed 3D fingerprint
    images.
  Figure 8 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_8.jpg
  Figure 8 caption: The 3D fingerprint surfaces are reconstructed (a) with normal
    amplification filter, (b) without normal amplification filter, and (c) without
    amplification filter using Poisson solver. The top views are in first row while
    the front views are on bottom row.
  Figure 9 Link: articels_figures_by_rev_year\2014\Towards_Contactless_LowCost_and_Accurate_D_Fingerprint_Identification\figure_9.jpg
  Figure 9 caption: (a) The ROC using 2D fingerprint images with different illumination
    (240 clients), (b) distribution of matching scores, (c) comparative performance
    from 3D minutiae matching strategies considered in experiments.
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.99
  Name of the first author: Ajay Kumar
  Name of the last author: Cyril Kwong
  Number of Figures: 12
  Number of Tables: 3
  Number of authors: 2
  Paper title: Towards Contactless, Low-Cost and Accurate 3D Fingerprint Identification
  Publication Date: 2014-07-16 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Touch-Based versus Contactless 2D3D Fingerprint Identification
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Individual and Combined Match Performance from 2D and 3D Fingerprint
      Images
  Table 3 caption:
    table_text: TABLE 3 3D and 2D Fingerprint Correspondence Probabilities
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2339818
- Affiliation of the first author: computer science department, chung-ang university,
    seoul 156-756, korea
  Affiliation of the last author: computer science department, university of california
    los angeles, los angeles, ca
  Figure 1 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_1.jpg
  Figure 1 caption: '[Integral Invariant] The graphical illustration for the computation
    of the proposed shape feature based on the Gaussian kernel at four different sample
    locations on a synthetic shape example. The circular shape represents a Gaussian
    kernel and the while region represents a shape. The value of the shape feature
    at each point in the shape region is obtained by the integration of the multiplication
    between the Gaussian kernel and the characteristic function for the complementary
    region of the shape, and is represented by the area colored in green with a Gaussian
    weight. It may be noted that the shape feature value at point c is zero since
    there is no overlap between the characteristic kernel and the complementary region
    of the shape and the shape feature value at point a is greater than the shape
    feature value at point b .'
  Figure 10 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_10.jpg
  Figure 10 caption: '[Evaluation] The graphical illustration of the quantitative
    evaluation for the shape categorization tasks using four different algorithms
    that are moment invariants, shape contexts, integral invariants using single scale,
    and our shape signature using multiscale integral invariants based on (a) the
    area under the ROC curves and (b) Bullseye measure. The algorithms are performed
    on the data set that consists of 10 (transformations) times 70 (categories) times
    20 (shapes) = 14,000 shapes. In each graph, the x-axis represents the index of
    the shape category arranged by the performance, and the y -axis represents the
    performance measure that is the area under the ROC curves for (a) and Bullseye
    measure for (b). The color of the curves represents the method. The overall performance
    of our shape signatures is shown to be better than the other three methods.'
  Figure 2 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_2.jpg
  Figure 2 caption: "[Shape feature] Examples of the proposed shape features for a\
    \ synthetic shape at multiple feature scales based on Gaussian kernels. (a) Original\
    \ shape. (b)\u2013(e) Shape features based on Gaussian kernels with from finer\
    \ to coarser feature scales and the feature values are represented using a color\
    \ coding scheme that ranges from blue for 0 to red for 1 as the shape feature\
    \ value ranges from 0 to 1."
  Figure 3 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_3.jpg
  Figure 3 caption: "[Noisy shape] Examples of a shape and its noisy shapes at different\
    \ noise levels. (a) Original shape. (b)\u2013(e) Noisy shapes at varying levels\
    \ of additive Gaussian noise with the given standard deviation."
  Figure 4 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_4.jpg
  Figure 4 caption: '[Equivalent shape] Examples of equivalent shapes modulo various
    similarity transformations including rotations, translations, reflections, and
    uniform scaling.'
  Figure 5 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_5.jpg
  Figure 5 caption: '[Shape signature] (a) Shape signatures of the shapes presented
    in Fig. 3 based on Gaussian kernels at varying feature scales for different noise
    levels. (b) Shape signatures of the shapes presented in Fig. 4 based on Gaussian
    kernels at varying feature scales for various transformations.'
  Figure 6 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_6.jpg
  Figure 6 caption: Examples of shapes in MPEG7 shape data set that consists of 70
    different shape categories. One shape example is presented for each shape category
    that consists of 20 shapes deformed by a combination of various rigid and non-rigid
    transformations. Note that shapes in the data set are not necessarily compact
    regions. Some shapes have holes and are disconnected.
  Figure 7 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_7.jpg
  Figure 7 caption: Shape distance is computed based on the shape signature using
    Wasserstein distance and pairwise distances among shapes are presented in the
    form of matrix. (a) Shape signatures for the shapes in Fig. 6 in the range of
    768 feature scales. The feature value ranges from 0 to 1 and the values are represented
    using a color coding scheme where blue is for 0 and red is for 1. The x-axis represents
    the index for the shape (from 1 to 70), and the y-axis represents the index for
    the feature scale (from 1 to 768). (b) Confusion matrix that computes a mutual
    distance between each pair of shapes in Fig. 6. The shape distance is normalized
    from 0 to 1 and the values are illustrated in a graphical way using a color coding
    scheme where blue is for 0 and red is for 1.
  Figure 8 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_8.jpg
  Figure 8 caption: Twenty different shape images within one example of shape categories
    (horse) in the original shape data set where a variety of deformations exist in
    the same object category. Note that shapes within the same category may have different
    topological properties in that some shapes are simply connected regions and others
    have holes or are multiply connected regions.
  Figure 9 Link: articels_figures_by_rev_year\2014\Shape_Matching_Using_Multiscale_Integral_Invariants\figure_9.jpg
  Figure 9 caption: An example set of shapes that are obtained by applying a similarity
    transformation to the shapes in Fig. 8. A combination of transformations in the
    similarity transformation which includes translation, rotation, reflection and
    uniform scaling with random parameters is applied to each shape.
  First author gender probability: 0.61
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Byung-Woo Hong
  Name of the last author: Stefano Soatto
  Number of Figures: 15
  Number of Tables: 0
  Number of authors: 2
  Paper title: Shape Matching Using Multiscale Integral Invariants
  Publication Date: 2014-07-23 00:00:00
  Table 1 caption:
    table_text: Not Available
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2342215
- Affiliation of the first author: "computer vision laboratory, ic faculty, \xE9cole\
    \ polytechnique f\xE9d\xE9rale de lausanne (epfl), lausanne ch-1015, switzerland"
  Affiliation of the last author: "computer vision laboratory, ic faculty, \xE9cole\
    \ polytechnique f\xE9d\xE9rale de lausanne (epfl), lausanne ch-1015, switzerland"
  Figure 1 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_1.jpg
  Figure 1 caption: Convolutional filter bank (a) learned for the extraction of curvilinear
    structures in retinal scan images, along with its separable approximation (b).
    The full-rank filters of (a) can be approximated very precisely as linear combinations
    of the far fewer separable filters of (b). This allows us to use this property
    to considerably speed up extraction of learned image features compared with convolutions
    with the original non-separable filters, even when Fast Fourier Transform is used
    for both the 2D and the 3D case, as it is shown by the figures in the bottom row.
  Figure 10 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_10.jpg
  Figure 10 caption: Convolutional filter banks for classification in 2D. (a) Learned
    non-separable filter bank from DRIVE dataset, (b) separable filter bank learned
    with the SEP-TD approach, (c) reconstructed filter bank. The non-separable filters
    can be approximated accurately using a smaller set of separable filters.
  Figure 2 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_2.jpg
  Figure 2 caption: 'Tensor decomposition for learning separable filters. Left: A
    bank of two-dimensional filters is stacked together to form a 3-dimensional tensor,
    Right: The tensor is decomposed in the sum of K rank-one tensors. Thus, the original
    filters are approximated by the weighted sum of the separable filters bf sk =
    bf ak circ bf bk .'
  Figure 3 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_3.jpg
  Figure 3 caption: Examples of 3D filter banks learned on the OPF data set [2]. (a)
    A 3D test image stack. (b) Response of the classifier trained on the separable
    filter bank output (d). (c) Non-separable filter bank learned by optimizing eq.
    (1). (d) The separable filter bank learned by optimizing eq. (7).
  Figure 4 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_4.jpg
  Figure 4 caption: Number of operations per pixel to compute convolutions, as a function
    of the filters size. (a) An image of 488times 488 pixels is convolved with a filter
    bank of J = 121 non-separable filters and K = 25 separable ones. (b) A volume
    of 114times 114times 50 voxels is convolved with a filter bank of J = 121 non-separable
    filters and K = 25 separable ones. The theoretical values are very similar to
    the experimental time shown in Fig. 1 and they show that the number of operations
    needed to compute the convolutions with our approach is smaller than both spatial
    convolution and FFT based convolution.
  Figure 5 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_5.jpg
  Figure 5 caption: Time needed to compute convolutions using a multi-thread MATLAB
    implementation, as a function of the filters size. (a) An image of 488times 488
    pixels is convolved with a filter bank of J = 121 non-separable filters and K
    = 25 separable ones. (b) A volume of 114times 114times 50 voxels is convolved
    with a filter bank of J = 121 non-separable filters and K = 25 separable ones.
    Using parallel computation the time needed to compute the convolution is further
    reduced and our methods are still the most efficient ones. The times are averaged
    over five repetitions.
  Figure 6 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_6.jpg
  Figure 6 caption: Representative images from the 2D medical data sets considered,
    together with the corresponding pixel classification results obtained with our
    SEP-COMB method.
  Figure 7 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_7.jpg
  Figure 7 caption: Approximating an existing filter bank. (a) The 36 separable filters
    learned by SEP-COMB to approximate a bank of 256 filters learned with the K-SVD
    algorithm of [13]. (b) Comparison between some of the original filters learned
    by K-SVD (top row) and their approximations reconstructed by our algorithm (bottom
    row). While filters with a regular structure are very well approximated, noisy
    filters are slightly smoothed by the approximation. Their role in the denoising
    process is, however, marginal, and therefore this engenders no performance penalty.
  Figure 8 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_8.jpg
  Figure 8 caption: Filters used in convolutional neural networks. (a) Twelve filters
    going out of a node of the second convolutional layer. (b) A set of four separable
    filters obtained after tensor decomposition. (c) Comparison of the original and
    the approximated filters.
  Figure 9 Link: articels_figures_by_rev_year\2014\Learning_Separable_Filters\figure_9.jpg
  Figure 9 caption: Some training images from the Drone Detection dataset. A convolutional
    neural network is trained to classify images containing a rotorcraft drone. Separable
    filters can be used to speed up the execution time of the convolutional layers.
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.99
  Name of the first author: Amos Sironi
  Name of the last author: Pascal Fua
  Number of Figures: 13
  Number of Tables: 6
  Number of authors: 5
  Paper title: Learning Separable Filters
  Publication Date: 2014-07-25 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Summary of the Different Methods Used for Our Experiments,
      as Described in Section 5.3
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Analytic Measure of the Performance of the Pixel Classification
      Task over Different Data Sets
  Table 3 caption:
    table_text: TABLE 3 Analytic Measure of the Performance of the Voxel Classification
      Task over the OPF Data Set
  Table 4 caption:
    table_text: TABLE 4 Results for the Image Denoising Task
  Table 5 caption:
    table_text: TABLE 5 Handwritten Digit Recognition on MNIST Data Set with Convolutional
      Neural Networks
  Table 6 caption:
    table_text: TABLE 6 Drone Detection Task with Convolutional Neural Networks
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2014.2343229
