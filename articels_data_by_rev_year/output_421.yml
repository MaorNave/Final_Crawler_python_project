- Affiliation of the first author: school of aerospace, mechanical, and manufacturing
    engineering, rmit university, melbourne, vic, australia
  Affiliation of the last author: school of computer science, university of adelaide,
    adelaide, sa, australia
  Figure 1 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_1.jpg
  Figure 1 caption: Minimal subset sampling versus higher than minimal subset sampling.
    The data do not contain outliers [8]. The figure represents an extreme case where
    the span of the data samples is made deliberately small.
  Figure 10 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_10.jpg
  Figure 10 caption: Segmentation result for several sequence in the Hopkins 155 dataset
    where the proposed method was successful. The sample used to generate the best
    hypothesis is also shown.
  Figure 2 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_2.jpg
  Figure 2 caption: The variation in minimum estimation error with number of data
    points n for different sample sizes ( h ). The figure shows the mean results of
    100 experiments for each combination.
  Figure 3 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_3.jpg
  Figure 3 caption: The cumulative distribution function of estimation errors for
    2D line (a), (b) and 3D plane (c), (d) fitting using different sample sizes (
    h ). The data used for fundamental matrix estimation and the CDF of the median
    residuals are shown in (e), (f).
  Figure 4 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_4.jpg
  Figure 4 caption: The intermediate steps of the proposed method in a simple 2D line
    fitting example for h=4 . The model represented by the current sample is plotted
    to make the steps clear. Note that the vertices of the starting point (Step 1)
    are not members of the structure and the algorithm does not move away from the
    underlying structure after it is found (Step 6).
  Figure 5 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_5.jpg
  Figure 5 caption: (a) Example dataset used in the line fitting experiments together
    with the structures returned by the proposed method. (b) Variation of the clustering
    accuracy with the scale of noise for different algorithms. (c-d) Variation of
    the computation time with the scale of noise and the total number of points for
    different algorithms. (e) The effect of parameter beta of RCM on clustering accuracy
    for data with varying scale of noise.
  Figure 6 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_6.jpg
  Figure 6 caption: (a) Example dataset used in the plane fitting experiments together
    with the structures returned by the proposed method. (b) Variation of the clustering
    accuracy with the scale of noise for different algorithms. (c-d) Variation of
    the computation time with the scale of noise and the total number of points for
    different algorithms. (e) The clustering accuracy variation for MultiGS and LO-RANSAC
    when the sampling times for those methods are increased to 10 and 25 times that
    of the proposed method. (f) The Clustering Accuracy variation with scale of noise
    for the proposed algorithm with h set to p and p+2 .
  Figure 7 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_7.jpg
  Figure 7 caption: (a) Variation of clustering accuracy with sampling time (b) Inliers
    identified by the proposed method (c) Outliers identified by the proposed method.
  Figure 8 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_8.jpg
  Figure 8 caption: Two-view motion segmentation results for image sequences in dataset
    [25]. Line 1 shows the ground truth whereas lines 2 and 3 show the final HMSS
    samples selected and the clustering results of the proposed method. The outliers
    are marked in red.
  Figure 9 Link: articels_figures_by_rev_year\2015\Robust_Model_Fitting_Using_Higher_Than_Minimal_Subset_Sampling\figure_9.jpg
  Figure 9 caption: Qualitative results of multi-homography estimation. Line 1 is
    the ground truth where as lines 2 and 3 are segmentation results of the proposed
    method and RCM respectively. The outliers are marked in red.
  First author gender probability: 0.98
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Ruwan B. Tennakoon
  Name of the last author: David Suter
  Number of Figures: 12
  Number of Tables: 2
  Number of authors: 5
  Paper title: Robust Model Fitting Using Higher Than Minimal Subset Sampling
  Publication Date: 2015-06-22 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Multi-Homography Detection Results
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Percentage Clustering Error of 3D Motion Segmentation
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2448103
- Affiliation of the first author: chair for computer vision and pattern recognition,
    technical university munich boltzmannstrasse 3, garching, germany
  Affiliation of the last author: department of mathematics and informatics, j. selye
    university, komarno, slovakia
  Figure 1 Link: articels_figures_by_rev_year\2015\Realigning_D_and_D_Object_Fragments_without_Correspondences\figure_1.jpg
  Figure 1 caption: Sample results on 2D and 3D synthetic images.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2015\Realigning_D_and_D_Object_Fragments_without_Correspondences\figure_2.jpg
  Figure 2 caption: The evaluated error measures in ascending order on the synthetic
    datasets. The y -axis has logarithmic scale and the medians of error measure are
    also shown.
  Figure 3 Link: articels_figures_by_rev_year\2015\Realigning_D_and_D_Object_Fragments_without_Correspondences\figure_3.jpg
  Figure 3 caption: 'Top: Median of error measures obtained by the proposed method
    on the 2D and 3D synthetic datasets in case of various type of error. Bottom:
    Sample observations with degradations.'
  Figure 4 Link: articels_figures_by_rev_year\2015\Realigning_D_and_D_Object_Fragments_without_Correspondences\figure_4.jpg
  Figure 4 caption: Sample observations for various strength of deformations (in rows)
    and different number of fragments (in columns).
  Figure 5 Link: articels_figures_by_rev_year\2015\Realigning_D_and_D_Object_Fragments_without_Correspondences\figure_5.jpg
  Figure 5 caption: "Plots of error measures ( \u03F5 and \u03B4 ) in ascending order\
    \ for 1,000 randomly generated testcases for different number of fragments and\
    \ \u03BA ( y -axis has logarithmic scale)."
  Figure 6 Link: articels_figures_by_rev_year\2015\Realigning_D_and_D_Object_Fragments_without_Correspondences\figure_6.jpg
  Figure 6 caption: 'Solutions of the Tangram puzzle (the average runtime for an image
    was about 50 sec.). Top: Observation images were taken by a digital camera and
    then were thresholded. Middle: Solutions, found in the Tangram manual. Bottom:
    The scanned template silhouettes with overlaid contours of aligned fragments.'
  Figure 7 Link: articels_figures_by_rev_year\2015\Realigning_D_and_D_Object_Fragments_without_Correspondences\figure_7.jpg
  Figure 7 caption: Bone fracture reduction. (a), (b) Illustration of the robustness
    of the proposed method in case of jaw broken into two pieces. (c)-(e) Realignment
    of pelvic fractures in case of various number of fragments. (f) A failure case,
    when the method cannot find good alignment. In the last row the template is overlaid
    with red color on the realigned image.
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.99
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Csaba Domokos
  Name of the last author: Zoltan Kato
  Number of Figures: 7
  Number of Tables: 1
  Number of authors: 2
  Paper title: Realigning 2D and 3D Object Fragments without Correspondences
  Publication Date: 2015-06-29 00:00:00
  Table 1 caption:
    table_text: "TABLE 1 Mean ( \u03BC ), Std. Deviation ( \u03C3 ) and Median ( m\
      \ ) of Error Measures Obtained on the 2D and 3D Synthetic Datasets"
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2450726
- Affiliation of the first author: computer science department, drexel university,
    philadelphia, pa
  Affiliation of the last author: computer science department, drexel university,
    philadelphia, pa
  Figure 1 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_1.jpg
  Figure 1 caption: Surface orientation likelihood spherical panoramas. The illumination
    (a) and reflectance combine to form a complex reflectance map (b). When this is
    compared with the observed appearance of a pixel in an observation (c), we arrive
    at a nonparametric distribution of surface orientations (d). The green circles
    denote the true orientation of the corresponding pixels (sorted left to right,
    and color coded).
  Figure 10 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_10.jpg
  Figure 10 caption: Shape optimization iterations. The geometry estimate at several
    stages shows how inaccurate regions are carved away as the estimate tightens around
    the true shape.
  Figure 2 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_2.jpg
  Figure 2 caption: "Synthetic data. Our synthetic data are formed by rendering 10\
    \ shapes [9] with real-world BRDFs [28] under real-world illumination environments\
    \ [29]. As indicated by \u2020 and \u22C6 , a subset of the shown reflectances\
    \ and environments are used only in the single image case, or multiple image case,\
    \ respectively, while all others are used in both."
  Figure 3 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_3.jpg
  Figure 3 caption: Multi-scale geometry estimation. We partition the possible surface
    orientations into a geodesic hemisphere. By incrementally increasing the resolution
    of the hemisphere we avoid local minima. Our final step is a gradient-descent
    based minimization to fine-tune the result.
  Figure 4 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_4.jpg
  Figure 4 caption: Shape accuracy. Shapes with self occlusions, like Blob05 (b) and
    Blob01 present challenges to our algorithm, while simple shapes like Blob03 (a)
    are more reliably estimated.
  Figure 5 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_5.jpg
  Figure 5 caption: Reflectance accuracy. Some reflectances such as Gray Plastic (a)
    are consistently well recovered, while others such as acrylic paints (c) have
    challenging complexity.
  Figure 6 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_6.jpg
  Figure 6 caption: Reflectance accuracy over illumination size. For a specular material,
    the accuracy of the reflectance map increases as detail is added to the illumination
    map. Data points are shown as rendered spheres. The ground truth rendering is
    inset.
  Figure 7 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_7.jpg
  Figure 7 caption: Real-world results. We captured several objects in four different
    natural lighting environments, and aligned ground-truth normal maps. As we discuss
    in the text, differences in the lighting environments have a clear impact on the
    accuracy of the recovered geometry.
  Figure 8 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_8.jpg
  Figure 8 caption: Real-world reflectance results. Each entry in this table corresponds
    to the results shown in Fig. 7.
  Figure 9 Link: articels_figures_by_rev_year\2015\Shape_and_Reflectance_Estimation_in_the_Wild\figure_9.jpg
  Figure 9 caption: Nonparametric orientation consistency. When a point on the mesh
    (dashed) is close to the true surface (solid), the observations will agree (a),
    resulting in a dense orientation distribution with a clear peak (bright region).
    When the point is not yet well aligned, the observations will disagree (c), resulting
    in a flat, near-zero distribution.
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.8
  Name of the first author: Geoffrey Oxholm
  Name of the last author: Ko Nishino
  Number of Figures: 16
  Number of Tables: 3
  Number of authors: 2
  Paper title: Shape and Reflectance Estimation in the Wild
  Publication Date: 2015-06-29 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Synthetic Results Summary
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Synthetic Results Summary
  Table 3 caption:
    table_text: TABLE 3 Overview of Real World Results
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2450734
- Affiliation of the first author: department of signal theory and communications,
    universidad carlos iii de madrid, spain
  Affiliation of the last author: department of signal theory and communications,
    universidad carlos iii de madrid, spain
  Figure 1 Link: articels_figures_by_rev_year\2015\Laplace_Approximation_for_Divisive_Gaussian_Processes_for_Nonstationary_Regressi\figure_1.jpg
  Figure 1 caption: Experiment using the synthetic data set proposed in [17] with
    200 training samples. The estimated mean and twice the standard deviation are
    given for the standard GP prediction (dotted line). Median estimation is provided
    for EP-DGP (dashed-dotted line), L-DGP (dashed line), and MCMC-DGP (continuous
    line), along with the quantiles 0.023 and 0.977 .
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2015\Laplace_Approximation_for_Divisive_Gaussian_Processes_for_Nonstationary_Regressi\figure_2.jpg
  Figure 2 caption: Results of the time experiment using Hou data set with different
    training sizes. Error bars are shown to represent the training time for the standard
    GP (continuous line and narrower error bars), L-DGP (dashed line and wider error
    bars), VHGPR (dashed-dotted line), and EP-DGP (dotted line).
  Figure 3 Link: Not Available
  Figure 3 caption: Not Available
  Figure 4 Link: Not Available
  Figure 4 caption: Not Available
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: "Luis Mu\xF1oz-Gonzalez"
  Name of the last author: "An\xEDbal R. Figueiras-Vidal"
  Number of Figures: 2
  Number of Tables: 3
  Number of authors: 3
  Paper title: Laplace Approximation for Divisive Gaussian Processes for Nonstationary
    Regression
  Publication Date: 2015-07-06 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Characteristics of the Data Sets Used for the Experiments
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Experimental Test Results on Small and Medium Size Multidimensional
      Data Sets, Providing the Average NMSE, NMAE, and NLPD PlusMinus One Standard
      Deviation
  Table 3 caption:
    table_text: TABLE 3 Experimental Test Results on Data Sets Win and Par
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2452914
- Affiliation of the first author: department of electrical and computer engineering,
    national university of singapore, 4 engineering drive 3, singapore
  Affiliation of the last author: department of electrical and computer engineering,
    national university of singapore, 4 engineering drive 3, singapore
  Figure 1 Link: articels_figures_by_rev_year\2015\Flexible_Clustered_MultiTask_Learning_by_Learning_Representative_Tasks\figure_1.jpg
  Figure 1 caption: 'The correlation matrices of different methods: (a) Ground Truth,
    (b) STL, (c) Regularized MTL, (d) Dirty MTL, (e) Robust MTL, (f) Group MTFL, (g)
    FlexTClus, (h) MTRL, (i) CMTL, and (j) FCMTL. Darker color indicates higher correlation.'
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2015\Flexible_Clustered_MultiTask_Learning_by_Learning_Representative_Tasks\figure_2.jpg
  Figure 2 caption: The representative tasks and the corresponding assignment matrix
    Z obtained by the proposed method on the synthetic data set 2 and 3. Darker color
    indicates larger value.
  Figure 3 Link: articels_figures_by_rev_year\2015\Flexible_Clustered_MultiTask_Learning_by_Learning_Representative_Tasks\figure_3.jpg
  Figure 3 caption: The representative tasks and the corresponding assignment matrix
    Z obtained by the proposed method on the School data set by using 10 and 30 percent
    of the data as training data. Darker color indicates larger value. Please zoom-in
    the image for the best visual results.
  Figure 4 Link: articels_figures_by_rev_year\2015\Flexible_Clustered_MultiTask_Learning_by_Learning_Representative_Tasks\figure_4.jpg
  Figure 4 caption: The representative tasks and the corresponding assignment matrix
    mathbf Z obtained by the proposed method on the MHC-I data set by using 20 and
    40 percent of the data as training data. Darker color indicates larger value.
  Figure 5 Link: articels_figures_by_rev_year\2015\Flexible_Clustered_MultiTask_Learning_by_Learning_Representative_Tasks\figure_5.jpg
  Figure 5 caption: Illustration of the convergence of FCMTL. (a) Synthetic data set
    1. (b) Synthetic data set 2. (c) Synthetic data set 3. (d) School data set with
    10 percent data . (e) School data set with 30 percent data. (f) MHC-I data set
    with 20 percent data.
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.96
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.98
  Name of the first author: Qiang Zhou
  Name of the last author: Qi Zhao
  Number of Figures: 5
  Number of Tables: 6
  Number of authors: 2
  Paper title: Flexible Clustered Multi-Task Learning by Learning Representative Tasks
  Publication Date: 2015-07-06 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Mean and Standard Deviation of NMSE of All Methods on the
      Three Synthetic Data Sets
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: TABLE 2 Mean and Standard Deviation of NMSE of All Methods on the
      School Data Set
  Table 3 caption:
    table_text: TABLE 3 Mean Average Precision ( % ) for the 10 Molecules with Less
      Than 200 Training Samples Each in the MHC-I Data Set
  Table 4 caption:
    table_text: TABLE 4 Summarization of 42 Categories (Six Families) of the Caltech-UCSD
      Birds Data Set Used in Our Experiments
  Table 5 caption:
    table_text: TABLE 5 Mean AP ( % ) of All Methods on the Caltech-UCSD Birds Data
      Set by Running Experiments on 42 Categories (Six Families)
  Table 6 caption:
    table_text: TABLE 6 Computational Running Time (in Seconds)
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2452911
- Affiliation of the first author: pattern recognition laboratory, delft university
    of technology, delft, the netherlands
  Affiliation of the last author: pattern recognition laboratory, delft university
    of technology, delft, the netherlands
  Figure 1 Link: Not Available
  Figure 1 caption: Not Available
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: Not Available
  Figure 2 caption: Not Available
  Figure 3 Link: Not Available
  Figure 3 caption: Not Available
  Figure 4 Link: Not Available
  Figure 4 caption: Not Available
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Marco Loog
  Name of the last author: Marco Loog
  Number of Figures: Not Available
  Number of Tables: 5
  Number of authors: 1
  Paper title: Contrastive Pessimistic Likelihood Estimation for Semi-Supervised Classification
  Publication Date: 2015-07-06 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Full Names and Abbreviations of the 16 Data Sets from [81]
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: 'TABLE 2 Basic Data Set Properties: Number of Objects, Dimensionality
      of the Original Feature Vectors, Dimensionality after PCA ( d ), Number of Classes
      K , Sizes of the Largest and the Smallest Class, Number of Labeled ( N ), Unlabeled
      ( M ), and Test Objects in Every Run of Our Experiments, and Whether Are Features
      are Purely Discrete'
  Table 3 caption:
    table_text: TABLE 3 Results Calculated Based on the Log-Likelihoods from the 1,000
      Experiments per Data Set for the Supervised and Our Semi-Supervised Approach
  Table 4 caption:
    table_text: TABLE 4 Results Based on the Error Rates Obtained from the 1,000 Experiments
      per Data Set for the Supervised and Our Semi-Supervised Approach
  Table 5 caption:
    table_text: TABLE 5 Log-Likelihood and Error Rate Results Obtained from the 1,000
      Experiments per Data Set for the Ad Hoc Semi-Supervised Approach and its Comparison
      to Our Novel Semi-Supervised and Regular Supervised Approach
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2452921
- Affiliation of the first author: cornell university, computer science, ithaca, new
    york
  Affiliation of the last author: cornell university, computer science, ithaca, new
    york
  Figure 1 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_1.jpg
  Figure 1 caption: "Our method takes as input a stack of images captured with varying,\
    \ unknown illumination and computes a per-pixel statistic ( \u03BA ) over this\
    \ stack. This statistic is then combined with simple physical model of the local\
    \ geometry at each point and illumination to obtain an estimate of the local visibility.\
    \ Local visibility is then used together with the average image to obtain an estimate\
    \ for per-point albedo (reflectance), which itself can be used to compute illumination\
    \ for the original input images."
  Figure 10 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_10.jpg
  Figure 10 caption: Comparison of our method with W+Ret from the MIT benchmark. Results
    are for our first estimate of the albedo (i.e., ambient illumination is assumed
    to be zero) as this gave us the best results on the benchmark. We show here grayscale
    images as the benchmark uses grayscale versions of the decomposed images in its
    evaluation metric.
  Figure 2 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_2.jpg
  Figure 2 caption: Histogram of pixel intensities for two points of Tentacle over
    an image stack (only blue color channel). Notice that even though the two points
    have very similar albedos their histograms are quite different due to local visibility.
    Point A is mostly occluded with respect to the light source, so its intensity
    values are in general lower.
  Figure 3 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_3.jpg
  Figure 3 caption: "A point x on a Lambertian surface is observed by camera c and\
    \ illuminated by a distant, moving light source with intensity l d , and a constant\
    \ ambient term of intensity l a . The local visibility is approximated by a cone\
    \ with angle \u03B1 . If the light source angle \u03B8 d with the surface normal\
    \ n \u20D7 is larger than \u03B1 , light is blocked and does not reach point x\
    \ at the bottom of the valley."
  Figure 4 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_4.jpg
  Figure 4 caption: "\u03BA(\u03B1) for different ratios of ambient to direct light\
    \ f . Note that as f\u2192\u221E ( l d =0 ) we have a constant curve ( \u03BA\
    (\u03B1)=1 ) so information about \u03B1 cannot be recovered."
  Figure 5 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_5.jpg
  Figure 5 caption: A depiction of the full algorithm for computing the local visibility
    angle alpha and the reflectance rho . Arrows show how information flows in our
    pipeline. Starting with an image stack we compute mathcal E[I] and mathcal E[I2]
    , which are used to compute kappa . We then proceed to obtain a first estimate
    of the local visibility angle and reflectance, which are then refined using a
    non-linear optimization.
  Figure 6 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_6.jpg
  Figure 6 caption: Results of our algorithm (second estimate). Each column shows
    results from a different dataset. The rows show 1) sample images from the original
    dataset, 2) our estimated AO, 3) albedo, and 4) the illumination in the sample
    image.
  Figure 7 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_7.jpg
  Figure 7 caption: 3D printed test objects Tentacle and Lightwell, together with
    a quarter dollar coin (for scale). Black tape on the sides of Lightwell was added
    to reduce sub-surface scattering that resulted from light shining on the side
    of the object.
  Figure 8 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_8.jpg
  Figure 8 caption: 'Left: the statistic kappa computed for Tentacle . Right two images:
    Comparison of estimated AO with ground truth (computer generated). The background
    clutter is masked.'
  Figure 9 Link: articels_figures_by_rev_year\2015\Photometric_Ambient_Occlusion_for_Intrinsic_Image_Decomposition\figure_9.jpg
  Figure 9 caption: 'Comparison of LMSE error on the MIT intrinsic image dataset [28]
    (shorter bars are better, indicating less error). Compared algorithms are: Grayscale
    Retinex (GR-RET), Color Retinex (COL-RET), Weiss (W), Weiss+Retinex (W+RET), ours
    with only direct term ( kappa -D) and our second estimate containing direct and
    ambient terms ( kappa -DA).'
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.99
  Name of the first author: Daniel Hauagge
  Name of the last author: Noah Snavely
  Number of Figures: 15
  Number of Tables: 1
  Number of authors: 4
  Paper title: Photometric Ambient Occlusion for Intrinsic Image Decomposition
  Publication Date: 2015-07-08 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Local Mean Squared Error (LMSE) for Individual Images of Our
      Algorithm for the First (Only Direct Light) and Second Estimates (Direct and
      Ambient Term), Together with Results from Other Work When Available
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2453959
- Affiliation of the first author: school of information science and technology, sun
    yat-sen university, china
  Affiliation of the last author: school of electronic engineering and computer science,
    queen mary university of london, united kingdom
  Figure 1 Link: articels_figures_by_rev_year\2015\Towards_OpenWorld_Person_ReIdentification_by_OneShot_GroupBased_Verification\figure_1.jpg
  Figure 1 caption: 'The One-Shot Open-World Group-based Person Re-Identification
    Problem: It is assumed that only one image is available for each person on a small
    watch list. The orange dash line denotes the conventional closed-world person
    re-identification setting, where the probe set only contains the target people.
    Under the open-world person re-identification setting, there are a large amount
    of non-target imposters captured along with the target people on the watch list.
    Their images will also appear in the probe set and some of them will look visually
    similar to the target people (see those highlighted by green boxes). In general,
    the number of non-target imposters is unknown. In practice, it can be a known
    large number (as compared to the watch-list) but not a constant.'
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2015\Towards_OpenWorld_Person_ReIdentification_by_OneShot_GroupBased_Verification\figure_2.jpg
  Figure 2 caption: 'An illustration of the three types of knowledge transfer. There
    are four different variations among target and non-target data: 1) the target
    inter-class variations (green lines); 2) the selected inter-class variation between
    target and non-similar non-target images (grey lines); 3) the selected non-target
    intra-class variations (magenta lines); 4) the selected non-target inter-class
    variations (yellow lines). A magenta line and a green line denote an approximate
    target intra-inter class pair and is used in the knowledge transfer to enrich
    intra-class variation (Eq. (7)); a magenta line and a yellow line denote a target
    specific non-target intra-inter class pair to transfer knowledge to enrich inter-class
    variation (Eq. (10)); a green line and a grey line denote a group separation intra-inter
    class pair to transfer knowledge to enrich group separation (Eq. (13)).'
  Figure 3 Link: articels_figures_by_rev_year\2015\Towards_OpenWorld_Person_ReIdentification_by_OneShot_GroupBased_Verification\figure_3.jpg
  Figure 3 caption: Illustration of our local relative comparison. Among the six images,
    A and B belong to the same person whilst the other four are of four other people.
    See text for more details.
  Figure 4 Link: articels_figures_by_rev_year\2015\Towards_OpenWorld_Person_ReIdentification_by_OneShot_GroupBased_Verification\figure_4.jpg
  Figure 4 caption: For individual verification, if the query image is matched to
    a wrong target person (as shown by the dashed blue line), the match is incorrect.
    In contrast, for set verification, the match is correct as long as the query image
    is matched to one of the target people (as shown by the solid red line).
  Figure 5 Link: articels_figures_by_rev_year\2015\Towards_OpenWorld_Person_ReIdentification_by_OneShot_GroupBased_Verification\figure_5.jpg
  Figure 5 caption: Examples of Images for the four datasets. Images of each column
    are from the same person.
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.98
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.97
  Name of the first author: Wei-Shi Zheng
  Name of the last author: Tao Xiang
  Number of Figures: 5
  Number of Tables: 7
  Number of authors: 3
  Paper title: Towards Open-World Person Re-Identification by One-Shot Group-Based
    Verification
  Publication Date: 2015-07-08 00:00:00
  Table 1 caption:
    table_text: 'TABLE 1 One-Shot Individual Verification Results: True Target Rate
      in Percent against False Target Rate'
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: 'TABLE 2 One-Shot Set Verification Results: True Target Rate in Percent
      against False Target Rate'
  Table 3 caption:
    table_text: 'TABLE 3 Cost Comparison: Relative Comparison Learning on VIPeR'
  Table 4 caption:
    table_text: "TABLE 4 Effects of \u03B1 on t-LRDC (Eq. (20)): True Target Rate\
      \ (Percent) When FTR = 1%"
  Table 5 caption:
    table_text: "TABLE 5 Effects of \u03B2 on t-LRDC (Eq. (20)): True Target Rate\
      \ (Percent) When FTR = 1%"
  Table 6 caption:
    table_text: 'TABLE 6 Effects of the Similarity Threshold h (Eq. (3)) in t-LRDC:
      True Target Rate (Percent) When FTR = 1%'
  Table 7 caption:
    table_text: 'TABLE 7 Effects of the Local Modelling Neighbourhood Size k (Eq.
      (16)) in t-LRDC: True Target Rate (Percent) When FTR = 1%'
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2453984
- Affiliation of the first author: b-dat and cicaeet, school of information and control,
    nanjing university of information science and technology, nanjing, china
  Affiliation of the last author: department of electrical and computer engineering,
    national university of singapore, block e4, 08-27, engineering drive 3, singapore
  Figure 1 Link: articels_figures_by_rev_year\2015\A_Deterministic_Analysis_for_LRR\figure_1.jpg
  Figure 1 caption: "Investigating the success condition of LRR, adopting \u03BB=1\
    \ logn \u2212 \u2212 \u2212 \u2212 \u221A . (a) Visualization of the success condition\
    \ proved by Theorem 3.1. The white and black areas mean \u201Csucceed\u201D (i.e.,\
    \ \u03B3\u2264 \u03B3 \u2217 ) and \u201Cfail\u201D (i.e., \u03B3> \u03B3 \u2217\
    \ ), respectively. (b) The empirical condition verified by our simulations, in\
    \ terms of \u2225 U \u2217 ( U \u2217 ) T \u2212 V 0 V T 0 \u2225 F < 10 \u2212\
    6 . (c) The empirical condition for I \u2217 = I 0 to hold. Here, a column of\
    \ C \u2217 is determined to be nonzero if and only if its \u2113 2 norm is greater\
    \ than 10 \u22123 . (d) The empirical condition for the affinity matrix | U \u2217\
    \ ( U \u2217 ) T | to lead to correct subspace clustering, using NCut to produce\
    \ the final clustering results. The numbers plotted on the above figures are the\
    \ success rates collected from 100 random trials."
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2015\A_Deterministic_Analysis_for_LRR\figure_2.jpg
  Figure 2 caption: "Investigating the parameter \u03BB . \u201C \u03B1=1 \u201D refers\
    \ to the estimate of \u03BB=1 logn \u2212 \u2212 \u2212 \u2212 \u221A . \u201C\
    \ \u03BB min \u201D and \u201C \u03BB max \u201D respectively denote the lower\
    \ and upper bounds of the parameter \u03BB , using which LRR can be exactly successful\
    \ in recovering V 0 V T 0 and identifying the I 0 . (a) d=500 , \u03B3=0.1 , r\
    \ 0 =25 , and n is varying from 200 to 1500. (b) n=500 , \u03B3=0.1 , r 0 =25\
    \ , and d is varying from 200 to 1500. (c) d=n=500 , r 0 =25 , and \u03B3 is varying\
    \ from 0.05 to 0.35. (d) d=n=500 , \u03B3=0.1 , and r 0 is varying from 5 to 85.\
    \ The numbers plotted on the curves are averaged from 10 random trials."
  Figure 3 Link: Not Available
  Figure 3 caption: Not Available
  Figure 4 Link: Not Available
  Figure 4 caption: Not Available
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.57
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Guangcan Liu
  Name of the last author: Shuicheng Yan
  Number of Figures: 2
  Number of Tables: 1
  Number of authors: 5
  Paper title: A Deterministic Analysis for LRR
  Publication Date: 2015-07-08 00:00:00
  Table 1 caption:
    table_text: TABLE 1 Averaged Clustering Accuracy (Percent) on Hopkins155
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2453969
- Affiliation of the first author: tti-chicago, chicago, il
  Affiliation of the last author: department of computer science, university of toronto,
    toronto, on, canada
  Figure 1 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_1.jpg
  Figure 1 caption: 'The OpenStreetMap project: Free geographic data for the world.
    Left: Development and coverage of OpenStreetMap from 2006-2012. Right: Screenshot
    of JOSM, a popular OSM editor, showing the level of annotation detail for the
    intersection ''Mendelssohnplatz'' in Karlsruhe, Germany.'
  Figure 10 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_10.jpg
  Figure 10 caption: 'Selected frames on the subregion maps: Inference results for
    unambiguous sequences. The left most column shows the full map for each sequence,
    followed by zoomed in sections of the map showing the posterior distribution over
    time. The black line is the GPS trajectory and the concentric circles indicate
    the current GPS position. Grid lines are every 500 m. High probability is indicated
    with red while low probability regions are shown in blue.'
  Figure 2 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_2.jpg
  Figure 2 caption: 'Map Representation: This figure shows a simple street map (left)
    and its corresponding graph representation (right). Directed street segments are
    represented as nodes and edges define their connectivity.'
  Figure 3 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_3.jpg
  Figure 3 caption: "Street Segment: Each street segment has a start and end position\
    \ p 0 and p 1 , a length \u2113 , an initial heading of the street segment \u03B2\
    \ and a curvature parameter \u03B1= \u03C8 1 \u2212 \u03C8 0 \u2113 . For arc\
    \ segments c is the circle center, r is the radius and \u03C8 0 and \u03C8 1 are\
    \ the start and end angles of the arc. For linear segments, \u03B1=0 ."
  Figure 4 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_4.jpg
  Figure 4 caption: 'Approximate Inference: The sigmoidal shape of the street node
    transition probability allows for efficient inference as analytic approximations
    are effective in the tails and a Monte Carlo approximation can be applied for
    the central section which is very small in practice.'
  Figure 5 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_5.jpg
  Figure 5 caption: 'Ambiguous Sequences: Both 04 and 06 cannot be localized due to
    fundamental ambiguities. Sequence 04 consists of a short, straight driving sequence
    and 06 traverses a symmetric part of the map, resulting in two equally likely
    modes.'
  Figure 6 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_6.jpg
  Figure 6 caption: 'Simplification Threshold: Impact of the simplification threshold
    epsilon on localization accuracy (left) and computation time (right). See Section
    4.4.'
  Figure 7 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_7.jpg
  Figure 7 caption: 'Map Size: Driving time (left) and distance travelled (right)
    before localization as a function of the map size.'
  Figure 8 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_8.jpg
  Figure 8 caption: 'Localization accuracy with noise: Position and heading error
    with different noise levels, averaged over five independent samples of noise.'
  Figure 9 Link: articels_figures_by_rev_year\2015\MapBased_Probabilistic_Visual_SelfLocalization\figure_9.jpg
  Figure 9 caption: 'Selected frames on the subregion maps: Inference results for
    unambiguous sequences. The left most column shows the full map for each sequence,
    followed by zoomed in sections of the map showing the posterior distribution over
    time. The black line is the GPS trajectory and the concentric circles indicate
    the current GPS position. Grid lines are every 500 m. High probability is indicated
    with red while low probability regions are shown in blue.'
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: female
  Last author gender probability: 1.0
  Name of the first author: Marcus A. Brubaker
  Name of the last author: Raquel Urtasun
  Number of Figures: 12
  Number of Tables: 1
  Number of authors: 3
  Paper title: Map-Based Probabilistic Visual Self-Localization
  Publication Date: 2015-07-08 00:00:00
  Table 1 caption:
    table_text: 'TABLE 1 Quantitative Evaluation: Average Position and Heading Error
      and Driving Time until Localization'
  Table 10 caption:
    table_text: Not Available
  Table 2 caption:
    table_text: Not Available
  Table 3 caption:
    table_text: Not Available
  Table 4 caption:
    table_text: Not Available
  Table 5 caption:
    table_text: Not Available
  Table 6 caption:
    table_text: Not Available
  Table 7 caption:
    table_text: Not Available
  Table 8 caption:
    table_text: Not Available
  Table 9 caption:
    table_text: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2015.2453975
