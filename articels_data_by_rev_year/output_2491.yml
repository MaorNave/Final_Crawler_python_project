- Affiliation of the first author: ibm research, armonk, ny, usa
  Affiliation of the last author: ibm research, armonk, ny, usa
  Figure 1 Link: articels_figures_by_rev_year\2022\Learning_to_Guide_a_SaturationBased_Theorem_Prover\figure_1.jpg
  Figure 1 caption: Formulation of automated theorem proving as a RL problem. Given
    a conjecture and a set of axioms, TRAIL iteratively performs reasoning steps until
    a proof found (within a provided time budget). At each step, the proof state is
    passed to the learning agent to select an action, which is then used by the reasoner
    to execute and subsequently update the proof state.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2022\Learning_to_Guide_a_SaturationBased_Theorem_Prover\figure_2.jpg
  Figure 2 caption: Flow from clause vectorization through the policy network. The
    inputs to the policy network are the sets of conjecture clauses, processed clauses,
    and available actions. After processing their corresponding vectors through a
    set of fully connected layers, an attention matrix between processed clauses and
    available actions is computed. Given the attention matrix, TRAIL performs max
    pooling followed by a softmax to output a probability distribution over all possible
    actions.
  Figure 3 Link: articels_figures_by_rev_year\2022\Learning_to_Guide_a_SaturationBased_Theorem_Prover\figure_3.jpg
  Figure 3 caption: "DAG representation of the clause \u2200A,B,C. p(A)\u2228\xAC\
    q(B,f(A))\u2228q(C,f(A)) where variable labels are replaced with generic tokens\
    \ to ensure invariance to arbitrary variable renaming."
  Figure 4 Link: articels_figures_by_rev_year\2022\Learning_to_Guide_a_SaturationBased_Theorem_Prover\figure_4.jpg
  Figure 4 caption: Update staging in StagedGCN. Identically colored nodes are updated
    simultaneously. Updates start from the leaf nodes (blue nodes), then proceed to
    green nodes, pink nodes, yellow nodes, and finally red nodes.
  Figure 5 Link: articels_figures_by_rev_year\2022\Learning_to_Guide_a_SaturationBased_Theorem_Prover\figure_5.jpg
  Figure 5 caption: Completion ratio across iterations for different vectorizers on
    MPTP (left graph) and M2k (right graph).
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.99
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.99
  Name of the first author: Ibrahim Abdelaziz
  Name of the last author: Achille Fokoue
  Number of Figures: 5
  Number of Tables: 8
  Number of authors: 11
  Paper title: Learning to Guide a Saturation-Based Theorem Prover
  Publication Date: 2022-01-04 00:00:00
  Table 1 caption: TABLE 1 Hyperparameter Values
  Table 10 caption: Not Available
  Table 2 caption: TABLE 2 Number of Problems Solved in M2k and MPTP2078
  Table 3 caption: TABLE 3 Performance of Different Vectorizers in Terms of Problems
    Solved
  Table 4 caption: TABLE 4 Performance When Models are Trained and Tested on Distinct
    Datasets
  Table 5 caption: TABLE 5 StagedGCN Performance (Cumultative Problems Solved) Across
    Various Clause Embedding Sizes
  Table 6 caption: TABLE 6 Ablation Study of StagedGCN Comparing Cumulative Number
    of Problems Solved
  Table 7 caption: TABLE 7 Performance (Cumulative Problems Solved) When Varying Reward
    Sources, Reward Normalization, Bounding Rewards, and Exploration
  Table 8 caption: TABLE 8 Example Problems From MPTP Benchmark With TRAIL versus
    E-Prover Runtime (Seconds) and Proof Steps
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2022.3140382
- Affiliation of the first author: dut-ru international school of information science
    & engineering, dalian university of technology, dalian, china
  Affiliation of the last author: department of mathematics, sustech international
    center for mathematics, national center for applied mathematics shenzhen, southern
    university of science and technology, shenzhen, guangdong, china
  Figure 1 Link: articels_figures_by_rev_year\2022\A_General_Descent_Aggregation_Framework_for_GradientBased_BiLevel_Optimization\figure_1.jpg
  Figure 1 caption: An evaluation of the convergence behavior about the LL variable
    y . We compare our BDA with gradient-based BLO algorithm (i.e., RHG). We set the
    initial points ( x , y ) = (0, 0), n=50 and K=20 . x t denotes the UL variable
    at the t th UL iterations.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2022\A_General_Descent_Aggregation_Framework_for_GradientBased_BiLevel_Optimization\figure_2.jpg
  Figure 2 caption: "Illustrating the convergence behavior of gradient-based BLO algorithms\
    \ about the UL variable x . We set the initial points ( x , y ) = (0, 0), n=50\
    \ and K=20 . In the first subfigure, \u03C6 K (x) and \u03C6 \u2217 (x) denote\
    \ the UL objective with LL computational solution y K and the optimal LL solution\
    \ y \u2217 respectively. The second and third subfigures respectively show the\
    \ errors of UL objective (i.e., | \u03C6 K (x)\u2212 \u03C6 \u2217 (x)| ) and\
    \ UL variable (i.e., \u2225x\u2212 x \u2217 \u2225 ). The last subfigure illustrates\
    \ the relationship among Optimal solution (short for \u201COpt.\u201D, the red\
    \ star) and the iteration solutions of RHG and BDA."
  Figure 3 Link: articels_figures_by_rev_year\2022\A_General_Descent_Aggregation_Framework_for_GradientBased_BiLevel_Optimization\figure_3.jpg
  Figure 3 caption: "LL iteration curves of gradient-based BLO algorithms (T-RHG,\
    \ RHG and Ours) under three fixed x (i.e., x 0 , x 5 , x 20 ). y \u2217 (x) and\
    \ y \u2217 denote the optimal solution with and without relationship about x ."
  Figure 4 Link: articels_figures_by_rev_year\2022\A_General_Descent_Aggregation_Framework_for_GradientBased_BiLevel_Optimization\figure_4.jpg
  Figure 4 caption: Comparisons of BDA with RHG on ten different initial points. We
    set the dimensional n=50 and K=20 . The left subfigure show the iteration solution
    of different initial points. We select five different initial points and show
    the UL objective behavior on the right subfigure.
  Figure 5 Link: articels_figures_by_rev_year\2022\A_General_Descent_Aggregation_Framework_for_GradientBased_BiLevel_Optimization\figure_5.jpg
  Figure 5 caption: Comparing of our BDA under different settings, i.e., with and
    without projection operator (namely w Projection and wo Projection). We set n=50
    and K=20 .
  Figure 6 Link: articels_figures_by_rev_year\2022\A_General_Descent_Aggregation_Framework_for_GradientBased_BiLevel_Optimization\figure_6.jpg
  Figure 6 caption: The iteration curves of the developed BDA with different alpha
    settings (i.e., with Fixed alpha =0 , alpha =0.5 and Adaptive alpha =0.5k ). We
    set n=50 and K=20 .
  Figure 7 Link: articels_figures_by_rev_year\2022\A_General_Descent_Aggregation_Framework_for_GradientBased_BiLevel_Optimization\figure_7.jpg
  Figure 7 caption: Illustrating the validation loss (i.e., UL objectives F(mathbf
    x,mathbf y) ) for three bi-level based methods on few-shot classification task.
  Figure 8 Link: articels_figures_by_rev_year\2022\A_General_Descent_Aggregation_Framework_for_GradientBased_BiLevel_Optimization\figure_8.jpg
  Figure 8 caption: Evaluating the orthogonality under different constraints (i.e.,
    with Max-norm regularization and Spectral Normalization (SN for short)) on few-shot
    application.
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.71
  Name of the first author: Risheng Liu
  Name of the last author: Jin Zhang
  Number of Figures: 8
  Number of Tables: 4
  Number of authors: 5
  Paper title: A General Descent Aggregation Framework for Gradient-Based Bi-Level
    Optimization
  Publication Date: 2022-01-04 00:00:00
  Table 1 caption: TABLE 1 Comparing the Convergence Results Between our Method and
    Existing GBMs in Different Scenarios (i.e., BLO w and wo LLS Condition)
  Table 10 caption: Not Available
  Table 2 caption: TABLE 2 Data Hyper-Cleaning Accuracy of the Compared Methods on
    two Different Datasets, i.e., MNIST [44] and Fashion MNIST [45]
  Table 3 caption: "TABLE 3 Averaged Accuracy Scores \xB1 \xB1 Standard Deviation\
    \ of Various Methods (Model-Based Methods and Gradient-Based Bi-Level Methods)\
    \ on Few-Shot Classification Classification Problems (1-Shot and 5-Shot, i.e.,\
    \ M=1,5 M=1,5, N=5,20,30,40 N=5,20,30,40) on Omniglot"
  Table 4 caption: TABLE 4 The Few-Shot Classification Performances on MiniImageNet
    ( N=5 N=5 and M=1 M=1)
  Table 5 caption: Not Available
  Table 6 caption: Not Available
  Table 7 caption: Not Available
  Table 8 caption: Not Available
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2022.3140249
- Affiliation of the first author: nanyang technological unversity, singapore
  Affiliation of the last author: electrical engineering, mathematics & computer science,
    delft university of technology, delft, cd, the netherlands
  Figure 1 Link: articels_figures_by_rev_year\2022\Efficient_Variational_Bayes_Learning_of_Graphical_Models_With_Smooth_Structural_\figure_1.jpg
  Figure 1 caption: Graph representation of BASS.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2022\Efficient_Variational_Bayes_Learning_of_Graphical_Models_With_Smooth_Structural_\figure_2.jpg
  Figure 2 caption: "Message passing scheme for updating (a) q( s (1:N) jk ) (the\
    \ red dashed arrows), q( \u03C0 1 ) , q( A 00 ) , and q( A 11 ) (the blue dotted\
    \ arrows), (b) q( J (1:N) jk ) (the red dashed arrows) and q( \u03B1 jk ) (the\
    \ blue dotted arrow), and (c) q( \u03BA (1:N) j ) (the red dashed arrows) and\
    \ q(\u03B2) (the blue dotted arrow)."
  Figure 3 Link: articels_figures_by_rev_year\2022\Efficient_Variational_Bayes_Learning_of_Graphical_Models_With_Smooth_Structural_\figure_3.jpg
  Figure 3 caption: "Estimation of 200 randomly selected \u27E8 s (t) jk \u27E9 (i.e.,\
    \ zero pattern of the off-diagonal elements in K (1:T) ) as a function of iteration\
    \ number i for BASS when applying to synthetic data with P=20 and N=1000 without\
    \ and with simulated annealing. Half of the selected off-diagonal elements correspond\
    \ to the absent edges in the true graph and the other half correspond to the true\
    \ edges."
  Figure 4 Link: articels_figures_by_rev_year\2022\Efficient_Variational_Bayes_Learning_of_Graphical_Models_With_Smooth_Structural_\figure_4.jpg
  Figure 4 caption: Computational time as a function of dimension P . We fit a straight
    line to the logarithm of average run time in Table 1 versus the logarithm of P
    , and compute the slope. The slope provides an empirical measure of the time complexity.
  Figure 5 Link: articels_figures_by_rev_year\2022\Efficient_Variational_Bayes_Learning_of_Graphical_Models_With_Smooth_Structural_\figure_5.jpg
  Figure 5 caption: 'Results of the stock return data of 78 banks: (a) the number
    of edges as a function of time resulting from different methods; (b) the average
    number of connections for banks in US, Europe, and Asia-Pacific given by BASS.'
  Figure 6 Link: articels_figures_by_rev_year\2022\Efficient_Variational_Bayes_Learning_of_Graphical_Models_With_Smooth_Structural_\figure_6.jpg
  Figure 6 caption: Financial networks resulting from BASS from 2005 to 2013. The
    networks are time-varying. The banks are clustered according to their regions
    in an automatic fashion.
  Figure 7 Link: articels_figures_by_rev_year\2022\Efficient_Variational_Bayes_Learning_of_Graphical_Models_With_Smooth_Structural_\figure_7.jpg
  Figure 7 caption: Boxplots of the number of edges given by BASS and GMS for the
    first data set with MCI patients.
  Figure 8 Link: articels_figures_by_rev_year\2022\Efficient_Variational_Bayes_Learning_of_Graphical_Models_With_Smooth_Structural_\figure_8.jpg
  Figure 8 caption: Boxplots of the number of edges given by BASS and GMS for the
    second data set with Mild AD patients.
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.96
  Gender of the first author: female
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Hang Yu
  Name of the last author: Justin Dauwels
  Number of Figures: 8
  Number of Tables: 6
  Number of authors: 3
  Paper title: Efficient Variational Bayes Learning of Graphical Models With Smooth
    Structural Changes
  Publication Date: 2022-01-06 00:00:00
  Table 1 caption: TABLE 1 Graph Recovery Results From Different Methods for Synthetic
    Data With Different Dimensions ( P=20,100,500 P=20,100,500, N=1000 N=1000, N e
    =P Ne=P)
  Table 10 caption: Not Available
  Table 2 caption: TABLE 2 Graph Recovery Results From Different Methods for Synthetic
    Data With Different Sample Size ( P=20 P=20, N=500,1000,2000 N=500,1000,2000,
    N e =P Ne=P)
  Table 3 caption: TABLE 3 Graph Recovery Results From Different Methods for Synthetic
    Data With Different Density ( P=20 P=20, N=1000 N=1000, N e =10,20,40 Ne=10,20,40)
  Table 4 caption: TABLE 4 Graph Recovery Results From BASS and GMS for Synthetic
    Time Series With Different Dimensions ( P=20,100 P=20,100, N=1000 N=1000, N e
    =P Ne=P)
  Table 5 caption: TABLE 5 Graph Recovery Results From BASS and GMS for Synthetic
    Time Series With Different Lengths ( P=20 P=20, N=500,1000,2000 N=500,1000,2000,
    N e =P Ne=P)
  Table 6 caption: TABLE 6 Graph Recovery Results From BASS and GMS for Synthetic
    Time Series With Different Graph Density ( P=20 P=20, N=1000 N=1000, N e =10,20,40
    Ne=10,20,40)
  Table 7 caption: Not Available
  Table 8 caption: Not Available
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2022.3140886
- Affiliation of the first author: intelligent information media lab, toyota technological
    institute (tti), nagoya, japan
  Affiliation of the last author: intelligent information media lab, toyota technological
    institute (tti), nagoya, japan
  Figure 1 Link: Not Available
  Figure 1 caption: Not Available
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: Not Available
  Figure 2 caption: Not Available
  Figure 3 Link: Not Available
  Figure 3 caption: Not Available
  Figure 4 Link: Not Available
  Figure 4 caption: Not Available
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Muhammad Haris
  Name of the last author: Norimichi Ukita
  Number of Figures: 0
  Number of Tables: 0
  Number of authors: 3
  Paper title: "Erratum to \u201CDeep Back-Projection Networks for Single Image Super-Resolution\u201D"
  Publication Date: 2022-01-07 00:00:00
  Table 1 caption: Not Available
  Table 10 caption: Not Available
  Table 2 caption: Not Available
  Table 3 caption: Not Available
  Table 4 caption: Not Available
  Table 5 caption: Not Available
  Table 6 caption: Not Available
  Table 7 caption: Not Available
  Table 8 caption: Not Available
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2021.3128797
- Affiliation of the first author: department of computing, imperial college london,
    queens gate, london, u.k.
  Affiliation of the last author: department of information engineering and mathematics,
    university of siena, siena, si, italy
  Figure 1 Link: Not Available
  Figure 1 caption: Not Available
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: Not Available
  Figure 2 caption: Not Available
  Figure 3 Link: Not Available
  Figure 3 caption: Not Available
  Figure 4 Link: Not Available
  Figure 4 caption: Not Available
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 1.0
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Stefanos Zafeiriou
  Name of the last author: Marco Gori
  Number of Figures: 0
  Number of Tables: 0
  Number of authors: 9
  Paper title: 'Guest Editorial: Non-Euclidean Machine Learning'
  Publication Date: 2022-01-07 00:00:00
  Table 1 caption: Not Available
  Table 10 caption: Not Available
  Table 2 caption: Not Available
  Table 3 caption: Not Available
  Table 4 caption: Not Available
  Table 5 caption: Not Available
  Table 6 caption: Not Available
  Table 7 caption: Not Available
  Table 8 caption: Not Available
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2021.3129857
- Affiliation of the first author: microsoft research asia, beijing, china
  Affiliation of the last author: department of computer science, cornell university,
    ithaca, ny, usa
  Figure 1 Link: Not Available
  Figure 1 caption: Not Available
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: Not Available
  Figure 2 caption: Not Available
  Figure 3 Link: Not Available
  Figure 3 caption: Not Available
  Figure 4 Link: Not Available
  Figure 4 caption: Not Available
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.97
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Jingdong Wang
  Name of the last author: Serge Belongie
  Number of Figures: 0
  Number of Tables: 0
  Number of authors: 5
  Paper title: 'Guest Editorial: Introduction to the Special Section on Fine-Grained
    Visual Categorization'
  Publication Date: 2022-01-07 00:00:00
  Table 1 caption: Not Available
  Table 10 caption: Not Available
  Table 2 caption: Not Available
  Table 3 caption: Not Available
  Table 4 caption: Not Available
  Table 5 caption: Not Available
  Table 6 caption: Not Available
  Table 7 caption: Not Available
  Table 8 caption: Not Available
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2021.3065094
- Affiliation of the first author: australian national university, canberra, act,
    australia
  Affiliation of the last author: australian national university, canberra, act, australia
  Figure 1 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_1.jpg
  Figure 1 caption: Given a satellite image (a), our method first estimates the height
    distribution (b), where lighter is higher, and then differentiably projects the
    satellite image to the ground-level viewpoint (c) according to the estimated height
    distribution. Conditioned on the projected image, our generator synthesizes a
    realistic street-view panorama (d) that is geometrically consistent with the satellite
    image, and very similar to the real street-view image (e).
  Figure 10 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_10.jpg
  Figure 10 caption: Qualitative comparison of images synthesized by our method with
    learned height maps (Ours) and with height maps fixed to zero (Ours wo Height
    (Projection)).
  Figure 2 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_2.jpg
  Figure 2 caption: Visualization of different projection approaches by a satellite
    camera and a street-view spherical camera. The former is a parallel projection
    in the overhead view, and the latter is an equirectangular projection at ground
    level.
  Figure 3 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_3.jpg
  Figure 3 caption: Corresponding pixels in a pair of satellite and street-view images.
    When a point p in the world coordinate is visible in both the satellite and street-view
    images, there is a deterministic geometric mapping between the projected pixels
    p sat and p str .
  Figure 4 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_4.jpg
  Figure 4 caption: Flowchart of the proposed framework. We propose a novel satellite
    to street-view image projection module to transform the satellite images to the
    street viewpoint and a projection-conditioned generator to synthesize realistic
    street-view panoramas that are geometrically consistent with the satellite images.
  Figure 5 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_5.jpg
  Figure 5 caption: Illustration of the geometry projection block in our S2SP module.
    We first construct an overhead-view MPI according to the given satellite image
    and the estimated height probability distribution, and then convert it to the
    street viewpoint by unrolling and stretching each concentric cylinder. The final
    street-view image is rendered in a back-to-front order from the street-view MPI.
  Figure 6 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_6.jpg
  Figure 6 caption: 'Example of satellite and street-view image misalignment and correction:
    (a) original satellite image, (b) projected satellite image according to the original
    satellite image center, (c) projected satellite image after mitigating the satellite
    and street-view image misalignment, and (d) corresponding street-view image in
    the database. The height maps are set to zero for this visualization.'
  Figure 7 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_7.jpg
  Figure 7 caption: 'Visualization of satellite and street-view image pair misalignment:
    (a) original satellite image with image center O 1 ; (b) projected street-view
    image in the overhead view with image center O 2 ; and (c) overlaid image of (a)
    and (b). There is a location shift between O 1 and O 2 .'
  Figure 8 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_8.jpg
  Figure 8 caption: Qualitative comparison of synthesized images for the CVACT (Aligned)
    and CVUSA datasets.
  Figure 9 Link: articels_figures_by_rev_year\2022\GeometryGuided_StreetView_Panorama_Synthesis_From_Satellite_Imagery\figure_9.jpg
  Figure 9 caption: Additional qualitative results with height maps (lighter is higher),
    projected satellite images generated by our S2SP module, and synthesized images
    generated by our entire pipeline.
  First author gender probability: 0.55
  Gender of the first author: female
  Gender of the last author: male
  Last author gender probability: 0.67
  Name of the first author: Yujiao Shi
  Name of the last author: Hongdong Li
  Number of Figures: 14
  Number of Tables: 5
  Number of authors: 4
  Paper title: Geometry-Guided Street-View Panorama Synthesis From Satellite Imagery
  Publication Date: 2022-01-07 00:00:00
  Table 1 caption: TABLE 1 Quantitative Comparison With Existing Algorithms on the
    CVACT (Aligned) and CVUSA Datasets
  Table 10 caption: Not Available
  Table 2 caption: TABLE 2 Performance Comparison on the Aligned and Unaligned CVACT
    Dataset (Both Training and Testing)
  Table 3 caption: TABLE 3 Ablation Study on the CVACT (Aligned) and the CVUSA Dataset
  Table 4 caption: TABLE 4 Performance Comparison as the Number of Planes N N Varies
    on the CVACT (Aligned) and the CVUSA Dataset
  Table 5 caption: TABLE 5 Performance Investigation With Different Satellite to Street-View
    Projection Approaches on the CVACT (Aligned) Dataset
  Table 6 caption: Not Available
  Table 7 caption: Not Available
  Table 8 caption: Not Available
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2022.3140750
- Affiliation of the first author: school of computing and information technology,
    university of wollongong, wollongong, nsw, australia
  Affiliation of the last author: school of computer science, university of technology
    sydney, ultimo, nsw, australia
  Figure 1 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_1.jpg
  Figure 1 caption: Overview of the proposed dataset-driven unsupervised object discovery
    framework (DUODIS in short) for region-based instance image retrieval. Our framework
    consists of two (i.e., offline and online) parts. In the offline part, there are
    three kinds of paths. The detector construction path (in black) exploits the whole
    image dataset and constructs the base-detector repository and the object detectors
    for all pseudo-classes. The object discovery path (in red and dashed line) assigns
    relevant object detectors to each image and applies them to conduct object discovery.
    The iterative self-boosting path (in green) utilizes the detected regions to further
    enhance the whole framework. In the online part, once a query object is submitted,
    its features will be extracted to measure its similarity to each of the regions
    detected from the image dataset. The most similar images are then retrieved, with
    the matched object regions delineated. In instance image retrieval, it is usually
    assumed that a user will indicate the object to search for in a query image by
    a bounding box. This setting is followed in this paper.
  Figure 10 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_10.jpg
  Figure 10 caption: Retrieval performance of the proposed method when different ratios
    of images are sampled from a dataset to carry out our framework, i.e., the generation
    of pseudo-classes and their object detectors.
  Figure 2 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_2.jpg
  Figure 2 caption: Images randomly sampled from some pseudo-classes formed by the
    proposed local clustering process. The top, middle, and bottom parts show the
    pseudo-classes from the datasets of R Oxford, R Paris, and INSTRE, respectively.
    As seen, images containing the same object (bordered in green) can be clustered
    into the same pseudo-class. Meanwhile, some noisy images (bordered in red) can
    also be seen. The quality of the pseudo-classes will be iteratively improved by
    the proposed framework.
  Figure 3 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_3.jpg
  Figure 3 caption: 'Pseudo-class updating in the iterative self-boosting process:
    1) All the object regions discovered from the images of a pseudo-class are collected;
    2) The centrality measure [45] is applied to this region collection to identify
    an anchor region for this pseudo-class; 3) This anchor region is used to search
    for similar object regions from the whole dataset to generate an updated pseudo-class.
    As illustrated, the updated pseudo-class contains fewer false positive images
    than before.'
  Figure 4 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_4.jpg
  Figure 4 caption: Comparison of unsupervised object discovery methods by Recall
    on INSTRE by varying the IoU threshold.
  Figure 5 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_5.jpg
  Figure 5 caption: Examples of our retrieval results on R Oxford and R Paris. The
    top-9 retrieved images of four queries are demonstrated in the four parts ( a
    ) - ( d ), respectively. For each part, the result of the proposed framework (DUODIS)
    is shown in the first row and the one obtained by GeM [39] is shown in the second
    row. The images bordered in green are the true positives and those bordered in
    red are the false positives. The bounding boxes in yellow delineate the query-matched
    object regions discovered by our framework. Best viewed on color monitor or printout.
  Figure 6 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_6.jpg
  Figure 6 caption: Histograms of the similarity (measured in cosine value) between
    the weight vectors obtained by our approximation and the actual trained SVM classifier
    for each image. They are obtained from all the images in the datasets of R Oxford,
    R Paris, and INSTRE, respectively. The weight vectors are obtained based on the
    features extracted via VGG16 model and the SVM classifier is trained via the binary
    cross entropy loss (BCE).
  Figure 7 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_7.jpg
  Figure 7 caption: "mAPMABO versus the number of self-boosting iterations of the\
    \ proposed framework DUODIS. \u201C0\u201D denotes the initial framework without\
    \ self-boost. VGG16 [31] is used as feature extractor."
  Figure 8 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_8.jpg
  Figure 8 caption: "The impact of the average number of detected object regions per\
    \ image on retrieval performance. Tested on R Oxford and R Paris for both settings\
    \ of (a) \u201CMedium\u201D and (b) \u201CHard\u201D."
  Figure 9 Link: articels_figures_by_rev_year\2022\DatasetDriven_Unsupervised_Object_Discovery_for_RegionBased_Instance_Image_Retri\figure_9.jpg
  Figure 9 caption: Retrieval performance (by mAP) versus three key parameters ( t
    c , k c , and t c ) used in our framework on R Oxford and R Paris. VGG16 [31]
    is used as feature extractor.
  First author gender probability: 0.63
  Gender of the first author: male
  Gender of the last author: female
  Last author gender probability: 0.72
  Name of the first author: Zhongyan Zhang
  Name of the last author: Fang Chen
  Number of Figures: 12
  Number of Tables: 9
  Number of authors: 6
  Paper title: Dataset-Driven Unsupervised Object Discovery for Region-Based Instance
    Image Retrieval
  Publication Date: 2022-01-07 00:00:00
  Table 1 caption: TABLE 1 Statistics of the Retrieval Benchmarks Used in This Experiment
  Table 10 caption: Not Available
  Table 2 caption: TABLE 2 Comparison With the General-Purpose and Unsupervised Object
    Discovery Methods on INSTRE
  Table 3 caption: 'TABLE 3 Unsupervised Object Detection: Comparison (Using the Correct
    Localization) Between Our Method and Another Five Unsupervised Detection Methods
    on the Generic Object Detection Benchmark Dataset PASCAL VOC 2007'
  Table 4 caption: TABLE 4 Comparison With the State-of-the-Art Region-Based Instance
    Image Retrieval Methods (by mAP)
  Table 5 caption: TABLE 5 Comparison (by mAP) With the State-of-the-Art Region-Based
    Instance Image Retrieval Methods on R ROxford, R RParis, R ROxford+ R R1M, and
    R RParis+ R R1M [39]
  Table 6 caption: TABLE 6 Timing Result by Using Different Schemes to Construct Object
    Detectors
  Table 7 caption: TABLE 7 Retrieval Performance (mAP) by Using Different Schemes
    to Construct Object Detectors
  Table 8 caption: TABLE 8 Retrieval Performance (mAP) Obtained by Applying the Object
    Detectors Generated on One Dataset to Another Dataset of a Similar Nature
  Table 9 caption: TABLE 9 The Experiment to Demonstrate That Our Framework can Work
    Well With Post-Processing Techniques to Achieve Higher Retrieval Performance
  paper DOI: https://doi.org/10.1109/TPAMI.2022.3141433
- Affiliation of the first author: state key laboratory of information security (sklois),
    institute of information engineering, chinese academy of sciences, beijing, china
  Affiliation of the last author: school of computer science and technology, key laboratory
    of big data mining and knowledge management (bdkm), university of chinese academy
    of sciences, beijing, china
  Figure 1 Link: articels_figures_by_rev_year\2022\Rethinking_Collaborative_Metric_Learning_Toward_an_Efficient_Alternative_Without\figure_1.jpg
  Figure 1 caption: Heat map of performance results on MovieLens-100k in terms of
    K=10,20 . Please see Appendix C.3 for more results, available online.
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: articels_figures_by_rev_year\2022\Rethinking_Collaborative_Metric_Learning_Toward_an_Efficient_Alternative_Without\figure_2.jpg
  Figure 2 caption: "Performance comparisons on validation set of MovieLens-100k with\
    \ respect to different negative sampling strategies and different sampling numbers\
    \ U\u22081,3,5,8,10 . Please refer to Appendix C.2 for more results, available\
    \ online."
  Figure 3 Link: articels_figures_by_rev_year\2022\Rethinking_Collaborative_Metric_Learning_Toward_an_Efficient_Alternative_Without\figure_3.jpg
  Figure 3 caption: The graphical visualization of score distribution of positive
    and unobserved items on MovieLens-1m.
  Figure 4 Link: articels_figures_by_rev_year\2022\Rethinking_Collaborative_Metric_Learning_Toward_an_Efficient_Alternative_Without\figure_4.jpg
  Figure 4 caption: Fine-grained AUC performance with respect to two users on MovieLens-1m
    and Anime, respectively. Please refer to Appendix C.4.1 for more visualizations,
    available online.
  Figure 5 Link: articels_figures_by_rev_year\2022\Rethinking_Collaborative_Metric_Learning_Toward_an_Efficient_Alternative_Without\figure_5.jpg
  Figure 5 caption: Empirical converge analysis of testing AUC of all CML-based algorithms,
    reporting 100 epochs here.
  Figure 6 Link: articels_figures_by_rev_year\2022\Rethinking_Collaborative_Metric_Learning_Toward_an_Efficient_Alternative_Without\figure_6.jpg
  Figure 6 caption: Comparisons against average running time with respect to CML framework
    algorithms and SFCML(ours). The method closer to the center of the circle enjoys
    better efficiency. Note that, here the s, m, h and d represent the second, minute,
    hour and day respectively. Please see Appendix C.6 for more results, available
    online.
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.73
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 0.89
  Name of the first author: Shilong Bao
  Name of the last author: Qingming Huang
  Number of Figures: 6
  Number of Tables: 6
  Number of authors: 5
  Paper title: 'Rethinking Collaborative Metric Learning: Toward an Efficient Alternative
    Without Negative Sampling'
  Publication Date: 2022-01-07 00:00:00
  Table 1 caption: TABLE 1 A Summary of Key Notations and Descriptions in Ths Work
  Table 10 caption: Not Available
  Table 2 caption: TABLE 2 Basic Information of the Datasets
  Table 3 caption: TABLE 3 Performance Comparisons on MovieLens-100k, CiteULike and
    MovieLens-1m Datasets, Where - Means That we Cannot Complete the Experiments due
    to the Out-of-Memory Issue
  Table 4 caption: TABLE 4 Performance Comparisons on Steam-200k and Anime Datasets,
    Where - Means That we Cannot Complete the Experiments due to the Out-of-Memory
    Issue
  Table 5 caption: TABLE 5 Statistics Information of ml-100k Dataset With Different
    Preference Thresholds t t
  Table 6 caption: "TABLE 6 The Empirical Performance of AUC With Respect to Different\
    \ Preference Thresholds t\u22081,2,3,4,5 t\u22081,2,3,4,5 on MovieLens-100k"
  Table 7 caption: Not Available
  Table 8 caption: Not Available
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2022.3141095
- Affiliation of the first author: college of computer science and technology, nanjing
    university of aeronautics and astronautics, nanjing, china
  Affiliation of the last author: college of computer science and technology, nanjing
    university of aeronautics and astronautics, nanjing, china
  Figure 1 Link: articels_figures_by_rev_year\2022\CCMN_A_General_Framework_for_Learning_With_ClassConditional_MultiLabel_Noise\figure_1.jpg
  Figure 1 caption: Comparison of uPML (control algorithm) against five comparing
    algorithms with the Bonferroni-Dunn test. Algorithms not connected with uPML in
    the CD diagram are considered to have a significantly different performance from
    the control algorithm (CD = 2.8494 at 0.05 significance level).
  Figure 10 Link: Not Available
  Figure 10 caption: Not Available
  Figure 2 Link: Not Available
  Figure 2 caption: Not Available
  Figure 3 Link: Not Available
  Figure 3 caption: Not Available
  Figure 4 Link: Not Available
  Figure 4 caption: Not Available
  Figure 5 Link: Not Available
  Figure 5 caption: Not Available
  Figure 6 Link: Not Available
  Figure 6 caption: Not Available
  Figure 7 Link: Not Available
  Figure 7 caption: Not Available
  Figure 8 Link: Not Available
  Figure 8 caption: Not Available
  Figure 9 Link: Not Available
  Figure 9 caption: Not Available
  First author gender probability: 0.63
  Gender of the first author: male
  Gender of the last author: male
  Last author gender probability: 1.0
  Name of the first author: Ming-Kun Xie
  Name of the last author: Sheng-Jun Huang
  Number of Figures: 1
  Number of Tables: 3
  Number of authors: 2
  Paper title: 'CCMN: A General Framework for Learning With Class-Conditional Multi-Label
    Noise'
  Publication Date: 2022-01-07 00:00:00
  Table 1 caption: TABLE 1 Comparison Results Between Ub-HL, Ub-RL and Their Baselines
    Using Linear Models
  Table 10 caption: Not Available
  Table 2 caption: TABLE 2 Comparison Results Between the Proposed Method (Using Linear
    Model) and PML Methods
  Table 3 caption: TABLE 3 Friedman Statistics F F FF in Terms of Each Evaluation
    Metric and the Critical Value at 0.05 Significance Level ( Comparing Algorithms
    k=7 k=7, Data Sets N=8 N=8)
  Table 4 caption: Not Available
  Table 5 caption: Not Available
  Table 6 caption: Not Available
  Table 7 caption: Not Available
  Table 8 caption: Not Available
  Table 9 caption: Not Available
  paper DOI: https://doi.org/10.1109/TPAMI.2022.3141240
